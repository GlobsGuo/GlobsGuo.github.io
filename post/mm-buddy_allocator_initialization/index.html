<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>mm-buddy_allocator初始化 - Globs&#39; Catchall</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Globs Guo" /><meta name="description" content="在介绍伙伴系统之前，我们先看一下伙伴系统所需要的数据结构的初始化流程。 伙伴系统使用的数据结构主要有每个内存节点的内存信息和每个内存区域的内存" />






<meta name="generator" content="Hugo 0.58.3 with theme even" />


<link rel="canonical" href="https://globsguo.github.io/post/mm-buddy_allocator_initialization/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="mm-buddy_allocator初始化" />
<meta property="og:description" content="在介绍伙伴系统之前，我们先看一下伙伴系统所需要的数据结构的初始化流程。 伙伴系统使用的数据结构主要有每个内存节点的内存信息和每个内存区域的内存" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://globsguo.github.io/post/mm-buddy_allocator_initialization/" />
<meta property="article:published_time" content="2019-10-24T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-10-24T00:00:00+00:00" />
<meta itemprop="name" content="mm-buddy_allocator初始化">
<meta itemprop="description" content="在介绍伙伴系统之前，我们先看一下伙伴系统所需要的数据结构的初始化流程。 伙伴系统使用的数据结构主要有每个内存节点的内存信息和每个内存区域的内存">


<meta itemprop="datePublished" content="2019-10-24T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-10-24T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="8516">



<meta itemprop="keywords" content="kernel-sources,memory,zonelist,NODE_DATA,buddy-allocator," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="mm-buddy_allocator初始化"/>
<meta name="twitter:description" content="在介绍伙伴系统之前，我们先看一下伙伴系统所需要的数据结构的初始化流程。 伙伴系统使用的数据结构主要有每个内存节点的内存信息和每个内存区域的内存"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Globs&#39; Catchall</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Globs&#39; Catchall</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">mm-buddy_allocator初始化</h1>

      <div class="post-meta">
        <span class="post-time"> 2019-10-24 </span>
        
          <span class="more-meta"> 8516 words </span>
          <span class="more-meta"> 17 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li><a href="#1-内存节点">1. 内存节点</a>
<ul>
<li><a href="#1-1-stuct-pglist-data-node-data">1.1. stuct pglist_data *node_data[]</a></li>
<li><a href="#1-2-node-data-的初始化">1.2. <strong>node_data</strong> 的初始化</a>
<ul>
<li><a href="#1-2-1-setup-node-data">1.2.1. setup_node_data</a></li>
<li><a href="#1-2-2-free-area-init-node">1.2.2. free_area_init_node</a></li>
</ul></li>
<li><a href="#1-3-zonelist的初始化">1.3. zonelist的初始化</a>
<ul>
<li><a href="#1-3-1-build-zonelists">1.3.1. build_zonelists</a>
<ul>
<li><a href="#1-3-1-1-build-zonelists-in-node-order">1.3.1.1. build_zonelists_in_node_order</a></li>
<li><a href="#1-3-1-2-build-zonelists-in-zone-order">1.3.1.2. build_zonelists_in_zone_order</a></li>
<li><a href="#1-3-1-3-示例说明">1.3.1.3. 示例说明</a></li>
</ul></li>
<li><a href="#1-3-2-build-zonelist-cache">1.3.2. build_zonelist_cache</a>
<ul>
<li><a href="#1-3-2-1-zlcache的说明">1.3.2.1. zlcache的说明</a></li>
<li><a href="#1-3-2-2-zlcache的初始化">1.3.2.2. zlcache的初始化</a></li>
</ul></li>
<li><a href="#1-3-3-zonelist的额外说明">1.3.3. zonelist的额外说明</a></li>
</ul></li>
</ul></li>
<li><a href="#2-内存区域">2. 内存区域</a>
<ul>
<li><a href="#2-1-struct-zone">2.1. struct zone</a>
<ul>
<li><a href="#2-1-1-struct-zone的成员变量">2.1.1. struct zone的成员变量</a>
<ul>
<li><a href="#2-1-1-1-watermark">2.1.1.1. watermark</a>
<ul>
<li><a href="#2-1-1-1-1-wmark-low">2.1.1.1.1. WMARK_LOW</a></li>
<li><a href="#2-1-1-1-2-wmark-min">2.1.1.1.2. WMARK_MIN</a></li>
<li><a href="#2-1-1-1-3-wmark-high">2.1.1.1.3. WMARK_HIGH</a></li>
</ul></li>
<li><a href="#2-1-1-2-lowmem-reserve">2.1.1.2. lowmem_reserve</a></li>
<li><a href="#2-1-1-3-xx-pages">2.1.1.3. xx_pages</a>
<ul>
<li><a href="#2-1-1-3-1-spanned-pages">2.1.1.3.1. spanned_pages</a></li>
<li><a href="#2-1-1-3-2-present-pages">2.1.1.3.2. present_pages</a></li>
<li><a href="#2-1-1-3-3-managed-pages">2.1.1.3.3. managed_pages</a></li>
</ul></li>
<li><a href="#2-1-1-4-wait-table-xx">2.1.1.4. wait_table_xx</a></li>
</ul></li>
<li><a href="#2-1-2-内存区域的初始化">2.1.2. 内存区域的初始化</a></li>
</ul></li>
</ul></li>
<li><a href="#3-zone-pcp-init">3. zone_pcp_init</a>
<ul>
<li><a href="#3-1-boot-pageset">3.1. boot_pageset</a></li>
<li><a href="#3-2-rmqueue-bulk">3.2. rmqueue_bulk</a></li>
</ul></li>
<li><a href="#4-free-area的初始化">4. free_area的初始化</a>
<ul>
<li><a href="#4-1-init-currently-empty-zone">4.1. init_currently_empty_zone</a></li>
<li><a href="#4-2-memmap-init-zone">4.2. memmap_init_zone</a></li>
<li><a href="#4-3-free-all-bootmem">4.3. free_all_bootmem</a></li>
</ul></li>
<li><a href="#5-总结">5. 总结</a></li>
</ul>
</nav>
  </div>
</div>
    <div class="post-content">
      

<p>在介绍伙伴系统之前，我们先看一下伙伴系统所需要的数据结构的初始化流程。<br />
伙伴系统使用的数据结构主要有每个内存节点的内存信息和每个内存区域的内存信息。</p>

<h1 id="1-内存节点">1. 内存节点</h1>

<p>内存节点是内核管理物理内存的最上层抽象。对于NUMA系统，至少包含一个节点0。每个节点都有一个 <strong>struct pglist_data</strong> 对象指针，包含该节点的所有物理内存信息。</p>

<h2 id="1-1-stuct-pglist-data-node-data">1.1. stuct pglist_data *node_data[]</h2>

<p>x86架构下，变量 <strong>struct pglist_data *node_data[]</strong> 保存系统中的所有节点信息，定义在 <em>arch/x86/mm/numa.c</em> 中。</p>

<pre><code class="language-c">typedef struct pglist_data {
    /* 节点包含的所有zone信息 */
    struct zone node_zones[MAX_NR_ZONES];
    struct zonelist node_zonelists[MAX_ZONELISTS];
    int nr_zones;
#ifdef CONFIG_MEMORY_HOTPLUG
    /*
     * Must be held any time you expect node_start_pfn, node_present_pages
     * or node_spanned_pages stay constant.  Holding this will also
     * guarantee that any pfn_valid() stays that way.
     *
     * pgdat_resize_lock() and pgdat_resize_unlock() are provided to
     * manipulate node_size_lock without checking for CONFIG_MEMORY_HOTPLUG.
     *
     * Nests above zone-&gt;lock and zone-&gt;span_seqlock
     */
    spinlock_t node_size_lock;
#endif
    unsigned long node_start_pfn;
    unsigned long node_present_pages; /* total number of physical pages */
    unsigned long node_spanned_pages; /* total size of physical page
                         range, including holes */
    int node_id;
    wait_queue_head_t kswapd_wait;
    wait_queue_head_t pfmemalloc_wait;
    struct task_struct *kswapd; /* Protected by
                       mem_hotplug_begin/end() */
    int kswapd_max_order;
    enum zone_type classzone_idx;
#ifdef CONFIG_NUMA_BALANCING
    /* Lock serializing the migrate rate limiting window */
    spinlock_t numabalancing_migrate_lock;

    /* Rate limiting time interval */
    unsigned long numabalancing_migrate_next_window;

    /* Number of pages migrated during the rate limiting time interval */
    unsigned long numabalancing_migrate_nr_pages;
#endif
} pg_data_t;

</code></pre>

<h2 id="1-2-node-data-的初始化">1.2. <strong>node_data</strong> 的初始化</h2>

<p><em>arch/x86/include/asm/mmzone_64.h</em> 中定义了访问 <strong>node_data</strong> 变量的宏 <code>#define NODE_DATA(nid) (node_data[nid])</code> ，内核中的代码大多使用这个宏访问 <strong>node_data</strong> 变量。</p>

<h3 id="1-2-1-setup-node-data">1.2.1. setup_node_data</h3>

<p>函数 <code>setup_node_data</code> 负责分配 <strong>node_data</strong> 变量，进行一些成员的简单初始化，函数的调用路径如下：</p>

<ul>
<li><code>start_kernel</code> ,  <em>init/main.c</em>

<ul>
<li><code>setup_arch</code> ,  <em>arch/x86/kernel/setup.c</em></li>
<li><code>initmem_init</code> ,  <em>arch/x86/mm/numa_64.c</em>

<ul>
<li><code>x86_numa_init</code> ,  <em>arch/x86/mm/numa.c</em></li>
<li><code>numa_init</code> ,  <em>arch/x86/mm/numa.c</em>

<ul>
<li><code>x86_acpi_numa_init</code> ,  <em>arch/x86/mm/srat.c</em></li>
<li><code>acpi_numa_init</code> ,  <em>drivers/acpi/numa.c</em></li>
<li><code>numa_register_memblks</code> ,  <em>arch/x86/mm/numa.c</em></li>
<li><code>setup_node_data</code> ,  <em>arch/x86/mm/numa.c</em></li>
</ul></li>
</ul></li>
</ul></li>
</ul>

<p>需要说明的是，实际测试时，根据boot log， <code>x86_numa_init</code> 的执行过程如下：</p>

<pre><code class="language-C">void __init x86_numa_init(void)
{
    if (!numa_off) {      // 通常为false，即默认启用NUMA
#ifdef CONFIG_ACPI_NUMA   // x86-64通常为true
        /*
         numa_init函数执行时，会调用x86_acpi_numa_init函数，
         主要是转化ACPI的SRAT和SLIT的操作。从boot log来看，
         函数返回值为负数，导致numa_init函数退出 */
        if (!numa_init(x86_acpi_numa_init))
            return;
#endif
#ifdef CONFIG_AMD_NUMA  // x86-64为true
        /*
         amd_numa_init函数从北桥的PCI配置空间获取
         NUMA信息，如果返回值为负数 */
        if (!numa_init(amd_numa_init))
            return;
#endif
    }
    /* 函数执行dummy_numa_init */
    numa_init(dummy_numa_init);
}
</code></pre>

<p>也就是说，默认情况下，x86架构开启NUMA配置， <code>x86_numa_init</code> 函数首先执行 <code>x86_acpi_numa_init</code> 函数，尝试从ACPI的SRAT中获取NUMA信息，成功的话函数直接退出；否则再调用 <code>amd_numa_init</code> ，从北桥的PCI配置空间获取NUMA信息，成功的话直接退出；否则再调用 <code>dummy_numa_init</code> ，直接将 <strong>0 - max_pfn</strong> 范围的物理页框作为节点0(这个范围内可能有空洞)。</p>

<p>不论是哪种方式，成功获取到NUMA信息后，都会将其添加到 <strong>numa_meminofo</strong> 变量。这个变量由 <code>numa_init</code> 调用函数 <code>numa_register_memblks</code> 时作为参数传递，添加到 <strong>memblock</strong> 变量，同时传递给 <code>setup_node_data</code> 函数，即每个节点的起始页框索引。</p>

<pre><code class="language-C">/* Initialize NODE_DATA for a node on the local memory */
static void __init setup_node_data(int nid, u64 start, u64 end)
{
    const size_t nd_size = roundup(sizeof(pg_data_t), PAGE_SIZE);
    u64 nd_pa;
    void *nd;
    int tnid;

    /*
     * Don't confuse VM with a node that doesn't have the
     * minimum amount of memory:
     */
    if (end &amp;&amp; (end - start) &lt; NODE_MIN_SIZE)
        return;

    /* ZONE_ALIGN = 8MB */
    start = roundup(start, ZONE_ALIGN);

    printk(KERN_INFO &quot;Initmem setup node %d [mem %#010Lx-%#010Lx]\n&quot;,
           nid, start, end - 1);

    /*
     * Allocate node data.  Try node-local memory and then any node.
     * Never allocate in DMA zone.
     */
    nd_pa = memblock_alloc_nid(nd_size, SMP_CACHE_BYTES, nid);
    if (!nd_pa) {
        nd_pa = __memblock_alloc_base(nd_size, SMP_CACHE_BYTES,
                          MEMBLOCK_ALLOC_ACCESSIBLE);
        if (!nd_pa) {
            pr_err(&quot;Cannot find %zu bytes in node %d\n&quot;,
                   nd_size, nid);
            return;
        }
    }
    nd = __va(nd_pa);

    /* report and initialize */
    printk(KERN_INFO &quot;  NODE_DATA [mem %#010Lx-%#010Lx]\n&quot;,
           nd_pa, nd_pa + nd_size - 1);
    tnid = early_pfn_to_nid(nd_pa &gt;&gt; PAGE_SHIFT);
    /* 分配node_data的节点和当前内存节点不一致 */
    if (tnid != nid)
        printk(KERN_INFO &quot;    NODE_DATA(%d) on node %d\n&quot;, nid, tnid);

    node_data[nid] = nd;
    memset(NODE_DATA(nid), 0, sizeof(pg_data_t));
    NODE_DATA(nid)-&gt;node_id = nid;
    NODE_DATA(nid)-&gt;node_start_pfn = start &gt;&gt; PAGE_SHIFT;
    NODE_DATA(nid)-&gt;node_spanned_pages = (end - start) &gt;&gt; PAGE_SHIFT;

    node_set_online(nid);
}
</code></pre>

<h3 id="1-2-2-free-area-init-node">1.2.2. free_area_init_node</h3>

<p><code>setup_node_data</code> 函数只会初始化 <strong>pg_data_t</strong> 的部分成员变量(节点信息，起始页框信息)，其余成员变量的初始化在函数 <code>free_area_init_node</code> 完成，两个函数的调用路径的先后顺序如下：</p>

<ul>
<li><code>start_kernel</code> ,  <em>init/main.c</em>

<ul>
<li><code>setup_arch</code> ,  <em>arch/x86/kernel/setup.c</em></li>
<li><code>initmem_init</code> ,  <em>arch/x86/mm/numa_64.c</em>

<ul>
<li><code>x86_numa_init</code> ,  <em>arch/x86/mm/numa.c</em></li>
<li><code>numa_init</code> ,  <em>arch/x86/mm/numa.c</em>

<ul>
<li><code>x86_acpi_numa_init</code> ,  <em>arch/x86/mm/srat.c</em></li>
<li><code>acpi_numa_init</code> ,  <em>drivers/acpi/numa.c</em></li>
<li><code>numa_register_memblks</code> ,  <em>arch/x86/mm/numa.c</em></li>
<li><code>setup_node_data</code> ,  <em>arch/x86/mm/numa.c</em></li>
</ul></li>
</ul></li>
<li><code>x86_init.paging.pagetable_init</code> = <code>native_pagetable_init</code> ,  <em>arch/x86/kernel/x86_init.c</em>

<ul>
<li><code>paging_init</code> ,  <em>arch/x86/mm/init_64.c</em></li>
<li><code>zone_sizes_init</code> ,  <em>arch/x86/mm/init.c</em> , 初始化 max_zone_pfns数组，包含各个zone可以包含的最大的page数

<ul>
<li><code>free_area_init_nodes(max_zone_pfns)</code>,  <em>mm/page_alloc.c</em></li>
<li><code>free_area_init_node</code> ,  <em>mm/page_alloc.c</em></li>
</ul></li>
</ul></li>
<li><code>build_all_zonelists</code> ,  <em>mm/page_alloc.c</em></li>
<li><code>page_alloc_init</code> ,  <em>mm/page_alloc.c</em></li>
<li><code>mm_init</code> ,  <em>init/main.c</em></li>
<li><code>mem_init</code> , <em>arch/x86/mm/init_64.c</em></li>
<li><code>kmem_cache_init</code> ,  <em>mm/slub.c</em></li>
</ul></li>
</ul>

<p><code>setup_node_data</code> 使用的NUMA信息来自ACPI表或者BIOS-e820，可能包含空洞，PFN的范围不准确； <code>free_area_init_node</code> 使用的内存信息来自 <strong>struct memblock memblock</strong> 变量，用 <strong>memblock</strong> 的信息对NUMA信息进一步修正( <strong>memblock</strong> 定义在 <em>mm/memblock.c</em> 中，保存始化阶段通过 <code>memblock_reserve</code> 、 <code>memblock_set_node</code> 函数保留的内存信息)：</p>

<pre><code class="language-C">/*
 执行上面的函数路径时，
 @zones_size = NULL
 @zholes_size = NULL */
void __paginginit free_area_init_node(int nid, unsigned long *zones_size,
        unsigned long node_start_pfn, unsigned long *zholes_size)
{
    /* 获取指定nid的pg_data_t指针 */
    pg_data_t *pgdat = NODE_DATA(nid);
    unsigned long start_pfn = 0;
    unsigned long end_pfn = 0;

    /* pg_data_t should be reset to zero when it's allocated */
    /* struct pglist_data *node_data[MAX_NUMNODES] */
    WARN_ON(pgdat-&gt;nr_zones || pgdat-&gt;classzone_idx);

    pgdat-&gt;node_id = nid;
    pgdat-&gt;node_start_pfn = node_start_pfn;
#ifdef CONFIG_HAVE_MEMBLOCK_NODE_MAP    //true
    /*
     根据struct memblock memblock提供的信息获取给定
     node的起始页框。如果节点没有可用内存，起始
     和结束页框号都设置为0，并输出警告信息 */
    get_pfn_range_for_nid(nid, &amp;start_pfn, &amp;end_pfn);
#endif
    /*
     计算node中的所有页面数
     pgdata-&gt;node_spanned_pages = 页面总数
     pgdata-&gt;node_present_pages = 总数 - hole */
    calculate_node_totalpages(pgdat, start_pfn, end_pfn,
                  zones_size, zholes_size);
    /* x86_64下函数为空 */
    alloc_node_mem_map(pgdat);
#ifdef CONFIG_FLAT_NODE_MEM_MAP     //false
    printk(KERN_DEBUG &quot;free_area_init_node: node %d, pgdat %08lx, node_mem_map %08lx\n&quot;,
        nid, (unsigned long)pgdat,
        (unsigned long)pgdat-&gt;node_mem_map);
#endif
    /*
     初始化pgdata中的成员变量，以及包含的每个zone的信息
     @zones_size = NULL
     @zholes_size = NULL */
    free_area_init_core(pgdat, start_pfn, end_pfn,
                zones_size, zholes_size);
}
</code></pre>

<p>至此，变量 <strong>node_data</strong> 初始化完毕，包含的节点信息供后续的内存初始化操作使用。</p>

<h2 id="1-3-zonelist的初始化">1.3. zonelist的初始化</h2>

<p><code>start_kernel</code> 调用 <code>build_all_zonelists</code> 初始化内存区域表，即 <strong>pg_data_t</strong> 的 <strong>node_zonelists</strong> 成员。</p>

<p><code>build_all_zonelists</code> 调用 <code>__build_all_zonelists</code> ，后者分别调用 <code>build_zonelists</code> 和 <code>build_zonelist_cache</code> 完成zonelist的初始化：</p>

<pre><code class="language-C">static int __build_all_zonelists(void *data)
{
    int nid;
    int cpu;
    pg_data_t *self = data;

#ifdef CONFIG_NUMA
    /* node_load数组记录每个内存节点的负载情况 */
    memset(node_load, 0, sizeof(node_load));
#endif
    /*
     self指针在响应内存的热插拔时为pg_data_t，
     否则为NULL。这个分支用来执行内存的热插拔操作 */
    if (self &amp;&amp; !node_online(self-&gt;node_id)) {
        build_zonelists(self);
        build_zonelist_cache(self);
    }
    /* 为每个在线的节点创建zonelist，以及zlcache */
    for_each_online_node(nid) {
        pg_data_t *pgdat = NODE_DATA(nid);

        build_zonelists(pgdat);
        build_zonelist_cache(pgdat);
    }

    for_each_possible_cpu(cpu) {
        setup_pageset(&amp;per_cpu(boot_pageset, cpu), 0);

#ifdef CONFIG_HAVE_MEMORYLESS_NODES   // x86默认为false
        if (cpu_online(cpu))
            set_cpu_numa_mem(cpu, local_memory_node(cpu_to_node(cpu)));
#endif
    }

    return 0;
}
</code></pre>

<p><strong>struct zonelist</strong> 结构如下，</p>

<pre><code class="language-C">struct zonelist {
    struct zonelist_cache *zlcache_ptr;          // NULL or &amp;zlcache
    struct zoneref _zonerefs[MAX_ZONES_PER_ZONELIST + 1];
#ifdef CONFIG_NUMA
    struct zonelist_cache zlcache;               // optional ...
#endif
};
</code></pre>

<p><strong>MAX_ZONES_PER_ZONELIST</strong> 为系统中的节点数和zone类型数的乘积，假如系统中共有2各节点，zone有3种类型(DMA，DMA32，NORMAL)，则  <strong>_zonerefs</strong>  的长度为6 + 1 = 7。数组的最后一个元素总是设置为空，作为结束标志。</p>

<h3 id="1-3-1-build-zonelists">1.3.1. build_zonelists</h3>

<p><code>build_zonelists</code> 函数完成  <strong>pg_data_t</strong>  成员 <strong>struct zonelist node_zonelists[MAX_ZONELISTS]</strong> 的初始化工作。zonelist是页面请求操作的对象，即伙伴系统分配内存时的操作对象；其中第一个zone是首选目标，其余的zone是备选项，按照优先级降序排列。</p>

<p>NUMA系统中， <strong>MAX_ZONELISTS</strong> 为2，因为我们需要支持 <strong>__GFP_THISNODE</strong> ( <strong>__GFP_THISNODE</strong> 只会从当前节点分配内存)选项：</p>

<ul>
<li><p>node_zonelists[0]<br />
带有备选node的zonelist</p></li>

<li><p>node_zonelists[1]<br />
没有备选node的zonelist</p></li>
</ul>

<p>zonelist的备选node通过函数 <code>find_next_best_node</code> 确定：备选node不能已经包含在zonelist中，应该是距离当前节点次近的节点，不属于任何CPU的节点更佳——这些节点没有分配内存的压力。距离根据距离数组计算——数组中包含系统中所有节点间的距离。</p>

<pre><code class="language-C">static void build_zonelists(pg_data_t *pgdat)
{
    int j, node, load;
    enum zone_type i;
    nodemask_t used_mask;
    int local_node, prev_node;
    struct zonelist *zonelist;
    int order = current_zonelist_order;

    /* initialize zonelists */
    for (i = 0; i &lt; MAX_ZONELISTS; i++) {
        zonelist = pgdat-&gt;node_zonelists + i;
        /*
         为了加速zonelist的读取操作，_zonerefs包含
         正在读取的zone的索引，避免访问大的数据结构 */
        zonelist-&gt;_zonerefs[0].zone = NULL;
        zonelist-&gt;_zonerefs[0].zone_idx = 0;
    }

    /* NUMA-aware ordering of nodes */
    local_node = pgdat-&gt;node_id;
    load = nr_online_nodes;
    prev_node = local_node;
    nodes_clear(used_mask);
    /*
     代码中此变量的注释写道：
     创建zonelist时会按照zone type从高到低的顺序
     排列，可能出现高位内存即normal内存消耗殆尽，而
     DMA内存还没有使用的情况，导致页面的分配操作被
     较远的节点响应。
     结合下面的代码，这个数组用来记录创建zonelist时
     每个node出现的先后顺序，按照和当前节点的距离
     降序排列。 */
    memset(node_order, 0, sizeof(node_order));
    j = 0;

    /* 寻找可以作为备选节点的node */
    while ((node = find_next_best_node(local_node, &amp;used_mask)) &gt;= 0) {
        /*
         * We don't want to pressure a particular node.
         * So adding penalty to the first node in same
         * distance group to make it round-robin.
         */
        if (node_distance(local_node, node) !=
            node_distance(local_node, prev_node))
            node_load[node] = load;

        prev_node = node;
        /* load供find_next_best_node函数寻找下一个备选节点
           时作为参考依据 */
        load--;
        if (order == ZONELIST_ORDER_NODE)
            /*
             zonelist首先按照节点的距离排序，然后按照节点内
             zone类型排序。这种情况能够保证最大局部性：normal
             内存消耗完之后，继续消耗本节点内的DMA内存。最后
             才会转向其他的节点，但是可能会耗尽DMA内存。 */
            build_zonelists_in_node_order(pgdat, node);
        else
            node_order[j++] = node; /* remember order */
    }
    /*
     根据node_order数组按照距离由小到大添加所有节点
     同一类型的zone，这种方式可以避免耗尽DMA内存 */
    if (order == ZONELIST_ORDER_ZONE) {
        /* calculate node order -- i.e., DMA last! */
        build_zonelists_in_zone_order(pgdat, j);
    }
    /*
     创建支持GFP_THISNODE的zonelist，即没有备选节点的
     node_zonelists[1]。这种情况下，系统为非NUMA，只
     需要将节点0添加到zonelist两种即可 */
    build_thisnode_zonelists(pgdat);
}

</code></pre>

<p>可以看到，创建zonelist时，有两种策略，一种为了保证最大程度的局部性，即 <code>build_zonelists_in_node_order</code> ；一种为了避免DMA内存被耗尽，即 <code>build_zonelists_in_zone_order</code> 。两种策略可以通过grub参数“numa_zonelist_order”设置，也可以通过sysctl设置。</p>

<h4 id="1-3-1-1-build-zonelists-in-node-order">1.3.1.1. build_zonelists_in_node_order</h4>

<p><code>build_zonelists_in_node_order</code> 找到传入的 <strong>pgdata</strong> 的 <strong>node_zonelists[0]</strong> 中第一个没有设置(为NULL)的 <strong>_zonerefs</strong> ，即 <strong>_zonerefs</strong> 中的最后一个元素，然后将 <strong>zonelist</strong> 中包含的所有zone按照类型从高到低的顺序添加到 <strong>_zonerefs</strong> 中：</p>

<pre><code class="language-C">static void build_zonelists_in_node_order(pg_data_t *pgdat, int node)
{
    int j;
    struct zonelist *zonelist;

    zonelist = &amp;pgdat-&gt;node_zonelists[0];
    /* 获取_zonerefs中最后一个元素的索引j */
    for (j = 0; zonelist-&gt;_zonerefs[j].zone != NULL; j++)
        ;
    /* 将zonelist中的所有zone按照类型由高到低的顺序添加到
       _zonerefs中从j开始的位置 */
    j = build_zonelists_node(NODE_DATA(node), zonelist, j);
    /* 设置_zonerefs中的最后一个元素为空，作为结束标志 */
    zonelist-&gt;_zonerefs[j].zone = NULL;
    zonelist-&gt;_zonerefs[j].zone_idx = 0;
}
</code></pre>

<h4 id="1-3-1-2-build-zonelists-in-zone-order">1.3.1.2. build_zonelists_in_zone_order</h4>

<p><code>build_zonelists_in_zone_order</code> 则根据 <strong>node_order</strong> 数组中按照距当前节点的距离保存的内存节点先将同一类型的每个节点的所有zone添加，然后添加其他类型的zone，按照类型从高到低的顺序：</p>

<pre><code class="language-C">static void build_zonelists_in_zone_order(pg_data_t *pgdat, int nr_nodes)
{
    int pos, j, node;
    int zone_type;      /* needs to be signed */
    struct zone *z;
    struct zonelist *zonelist;

    zonelist = &amp;pgdat-&gt;node_zonelists[0];
    pos = 0;
    /* 按照zone类型从高到底的顺序 */
    for (zone_type = MAX_NR_ZONES - 1; zone_type &gt;= 0; zone_type--) {
        for (j = 0; j &lt; nr_nodes; j++) {
            node = node_order[j];
            z = &amp;NODE_DATA(node)-&gt;node_zones[zone_type];
            /* zone有效 */
            if (populated_zone(z)) {
                zoneref_set_zone(z,
                    &amp;zonelist-&gt;_zonerefs[pos++]);
                check_highest_zone(zone_type);
            }
        }
    }
    /* 设置最后一个_zonerefs为空，作为结束标志 */
    zonelist-&gt;_zonerefs[pos].zone = NULL;
    zonelist-&gt;_zonerefs[pos].zone_idx = 0;
}
</code></pre>

<h4 id="1-3-1-3-示例说明">1.3.1.3. 示例说明</h4>

<p>假设系统中有两个内存节点0和1，每个节点都有ZONE_DMA，ZONE_DMA32，ZONE_NORMAL三种类型的区域，则NODE_DATA(0)的<strong>zonelist-&gt;_zonerefs</strong>在两种情况下初始化后分别为：</p>

<ul>
<li>node order<br />
{ ZONE_NORMAL-0, ZONE_DMA32-0, ZONE_DMA-0，<br />
ZONE_NORMAL-1, ZONE_DMA32-1, ZONE_DMA-1 }</li>
<li>zone order<br />
{ ZONE_NORMAL-0, ZONE_NORMAL-1, ZONE_DMA32-0,<br />
ZONE_DMA32-1, ZONE_DMA-0, ZONE_DMA-1 }</li>
</ul>

<h3 id="1-3-2-build-zonelist-cache">1.3.2. build_zonelist_cache</h3>

<h4 id="1-3-2-1-zlcache的说明">1.3.2.1. zlcache的说明</h4>

<p><code>build_zonelist_cache</code> 初始化 <strong>struct zonelist</strong> 中的剩余两个成员变量： <strong>zlcache_ptr</strong> 和 <strong>zlcache</strong> 。</p>

<p><strong>struct zonelist_cache</strong> 缓存每个zonelist的关键信息，以便在<code>get_page_from_freelist()</code>函数中扫描空闲页面时减小高速缓存的footprint。</p>

<pre><code class="language-C">struct zonelist_cache {
    unsigned short z_to_n[MAX_ZONES_PER_ZONELIST];      /* zone-&gt;nid */
    DECLARE_BITMAP(fullzones, MAX_ZONES_PER_ZONELIST);  /* zone full? */
    unsigned long last_full_zap;        /* when last zap'd (jiffies) */
};
</code></pre>

<p>位图 <strong>fullzones</strong> 追踪上次zero&rsquo;d fullzones之后，zonelist中缺少空闲内存的zone信息。</p>

<p>数组 <strong>z_to_n[]</strong> 将zonelist中的每个zone映射到所属的节点的ID，以便快速确认该节点是否包含在当前进程的 <strong>mems_allowed</strong> 中。</p>

<p><strong>fullzones</strong> 和 <strong>z_to_n[]</strong> 都和zonelist一一对应，通过zonelist的  <strong>_zonerefs</strong> 提供的偏移量进行索引。</p>

<p><code>get_page_from_freelist</code> 函数执行两次扫描。第一次扫描时，跳过设置了 <strong>fullzones</strong> 中对应位的zone，以及对应的节点没有包含在 <strong>current-&gt;mems_allowed</strong> 中的zone。第二次扫描时，跳过 <strong>zonelist_cache</strong> ，保证查看了每个zone。</p>

<p>每一秒钟执行一次zero out(zap) fullzones的操作， <strong>last_full_zap</strong> 保存上一次zap操作的时间。这种机制可以减少zone刚刚进入低内存状态，不停地检测zone是否有空闲内存所花费的时间。</p>

<h4 id="1-3-2-2-zlcache的初始化">1.3.2.2. zlcache的初始化</h4>

<p>函数 <code>build_zonelist_cache</code> 完成zlcache的初始化，</p>

<pre><code class="language-C">static void build_zonelist_cache(pg_data_t *pgdat)
{
    struct zonelist *zonelist;
    struct zonelist_cache *zlc;
    struct zoneref *z;
    /*
     只需要初始化node_zonelists[0]，即有备选节点的
     zonelist；没有备选节点的zonelist不需要zlcache
     来减小zonelist的footprint */
    zonelist = &amp;pgdat-&gt;node_zonelists[0];
    /* zlcache_ptr指向自身的zlcache即可 */
    zonelist-&gt;zlcache_ptr = zlc = &amp;zonelist-&gt;zlcache;
    /* 初始化fullzones位图 */
    bitmap_zero(zlc-&gt;fullzones, MAX_ZONES_PER_ZONELIST);
    /* 将zonelist中的每个zone所属的节点信息保存在z_to_n[] */
    for (z = zonelist-&gt;_zonerefs; z-&gt;zone; z++)
        zlc-&gt;z_to_n[z - zonelist-&gt;_zonerefs] = zonelist_node_idx(z);
}
</code></pre>

<h3 id="1-3-3-zonelist的额外说明">1.3.3. zonelist的额外说明</h3>

<p><strong>struct zonelist_cache</strong> 的成员属于 <strong>struct zonelist</strong> 。但是， <strong>MPOL_BIND</strong> 内存策略的zonelist结构体长度不同，通常更短—— <strong>MPOL_BIND</strong> 策略不需要 <strong>zonelist_cache</strong> 成员，因此我们将固定长度的成员放在zonelist结构体的起始位置，以 <strong>zonelist_cache</strong> 结尾。</p>

<p><strong>zonelist_cache</strong> 这个可选的成员变量通过 <strong>zlcache_ptr</strong> 指针定位，在 <strong>MPOL_BIND</strong> 的情况下指针为NULL。</p>

<p>由此， <strong>strut zonelist</strong> 有两种形式：</p>

<ol>
<li>完整的，固定长度的版本</li>
<li>针对 <strong>MPOL_BIND</strong> 内存策略的版本( <strong>zlcache_ptr</strong> 为空)</li>
</ol>

<p>虽然存在多个CPU同时修改 <strong>zonelist_cache</strong> 的 <strong>fullzones</strong> 和 <strong>last_full_zap</strong> 的情况，我们没有加锁——这只是提示信息，如果这些信息有误，只不过会影响分配器的运行速度，但是不会影响分配器的功能。</p>

<h1 id="2-内存区域">2. 内存区域</h1>

<p>根据物理内存的使用方式，内核将物理内存分为多个内存区域(zone)，每个zone用 <strong>struct zone</strong> 来描述。以x86_64架构为例，内核包括ZONE_DMA，ZONE_DMA32，ZONE_NORMAL，ZONE_MOVABLE四种。</p>

<p>定义在 <em>include/linux/mmzone.h</em> 中的 <strong>zone_type</strong> ：</p>

<pre><code class="language-C">enum zone_type {
#ifdef CONFIG_ZONE_DMA
    /*
     用于不能寻址所有内存地址的DMA设备
     x86下为 &lt;16MB的地址 */
    ZONE_DMA,
#endif
#ifdef CONFIG_ZONE_DMA32
    /*
     x86_64同时支持只能在16MB以下的地址空间
     执行DMA操作的设备和可以在4GB以下的地址
     空间执行DMA操作的32bit设备，因此需要
     两个DMA内存区域 */
    ZONE_DMA32,
#endif
    ZONE_NORMAL,
#ifdef CONFIG_HIGHMEM
    /*
     只有内核将这些区域映射到自己的地址空间
     后才能正常访问，比如i386下内核要访问
     900MB以上的地址空间
     32bit的x86架构，为高于896MB的所有物理
     内存，其他架构为空 */
    ZONE_HIGHMEM,
#endif
    ZONE_MOVABLE,
    __MAX_NR_ZONES
}
</code></pre>

<h2 id="2-1-struct-zone">2.1. struct zone</h2>

<p>Linux内核用 <strong>struct zone</strong> 描述内存区域：</p>

<pre><code class="language-C">struct zone {
    unsigned long watermark[NR_WMARK];
    long lowmem_reserve[MAX_NR_ZONES];

#ifdef CONFIG_NUMA
    int node;  /* zone所属的内存节点 */
#endif
    unsigned int inactive_ratio;

    struct pglist_data *zone_pgdat;  /* zone所属的pg_data_t */
    struct per_cpu_pageset __percpu *pageset;
    unsigned long dirty_balance_reserve;
#ifdef CONFIG_NUMA
    /*
     * zone reclaim becomes active if more unmapped pages exist.
     */
    unsigned long       min_unmapped_pages;
    unsigned long       min_slab_pages;
#endif /* CONFIG_NUMA */
    unsigned long       zone_start_pfn; /* zone的起始PFN */

    unsigned long       managed_pages;
    unsigned long       spanned_pages;
    unsigned long       present_pages;

    const char      *name;  /* zone的名称 */
    int         nr_migrate_reserve_block;

    wait_queue_head_t   *wait_table;
    unsigned long       wait_table_hash_nr_entries;
    unsigned long       wait_table_bits;

    ZONE_PADDING(_pad1_)

    /* Write-intensive fields used from the page allocator */
    spinlock_t      lock;

    /* free areas of different sizes */
    struct free_area    free_area[MAX_ORDER];

    /* zone flags, see below */
    unsigned long       flags;

    ZONE_PADDING(_pad2_)
    /* Fields commonly accessed by the page reclaim scanner */
    spinlock_t      lru_lock;
    struct lruvec       lruvec;

    /* Evictions &amp; activations on the inactive file list */
    atomic_long_t       inactive_age;

    /*
     * When free pages are below this point, additional steps are taken
     * when reading the number of free pages to avoid per-cpu counter
     * drift allowing watermarks to be breached
     */
    unsigned long percpu_drift_mark;

    ZONE_PADDING(_pad3_)
    /* Zone statistics */
    atomic_long_t       vm_stat[NR_VM_ZONE_STAT_ITEMS];
};
</code></pre>

<h3 id="2-1-1-struct-zone的成员变量">2.1.1. struct zone的成员变量</h3>

<h4 id="2-1-1-1-watermark">2.1.1.1. watermark</h4>

<p>watermark数组长度为3，三个元素分别是WMARK_MIN，WMARK_LOW，WMARK_HIGH。</p>

<p>watermark的描述来自 <strong>undering the linux virtual memory manager</strong> 一书：</p>

<p>可用的内存少于LOW值， <strong>kswapd</strong> 程序就会被唤醒，执行页面释放操作。如果压力很大，进程会同步的释放内存，即direct-reclaim路径。</p>

<p>每一个区域都有一个watermark数组，追踪区域的内存压力。MIN值在内存初始化时通过函数 <code>free_area_init_core</code> 计算，通常是ZoneSizeInPages/128。</p>

<h5 id="2-1-1-1-1-wmark-low">2.1.1.1.1. WMARK_LOW</h5>

<p>区域的空闲页面数到达LOW时，伙伴分配器会唤醒 <strong>kswapd</strong> ，开始释放页面。LOW的默认值时MIN的两倍。</p>

<h5 id="2-1-1-1-2-wmark-min">2.1.1.1.2. WMARK_MIN</h5>

<p>到达MIN时，分配器会以同步的方式执行 <strong>kswapd</strong> 操作，被称作*direct-reclaim*路径。</p>

<h5 id="2-1-1-1-3-wmark-high">2.1.1.1.3. WMARK_HIGH</h5>

<p><strong>kswapd</strong> 唤醒之后，直到空闲页面的数量到达HIGH，内存区域才会被视为balanced，此时 <strong>kswapd</strong> 回到休眠状态。HIGH的默认值为MIN的三倍。</p>

<h4 id="2-1-1-2-lowmem-reserve">2.1.1.2. lowmem_reserve</h4>

<p>内核中的注释如下：</p>

<blockquote>
<p>我们不知道分配出去的内存最终是否会被释放，为了避免浪费数GB的内存，我们必须保留lower zone的内存，否则就有在lower zone出现OOM的风险，尽管在higher zone可能有大量可用的内存。</p>

<p>这个数组在运行时会随着 <strong>sysctl_lowmem_reserve_ratio</strong> 的变化而变化。</p>
</blockquote>

<p>根据之前的说明，较高区域的内存通常较大，较低区域的内存通常较小。这个数组用来限制每个内存区域应该保留的内存页的数量，避免在较低内存区域出现OOM的情况。</p>

<h4 id="2-1-1-3-xx-pages">2.1.1.3. xx_pages</h4>

<h5 id="2-1-1-3-1-spanned-pages">2.1.1.3.1. spanned_pages</h5>

<p><strong>spanned_pages</strong> 包含空洞，计算方法为 <code>spanned_pages = zone_end_pfn - zone_start_pfn</code> 。</p>

<h5 id="2-1-1-3-2-present-pages">2.1.1.3.2. present_pages</h5>

<p><strong>present_pages</strong> 是区域包含的物理页框数，不包含空洞，计算方法为 <code>present_pages = spanned_pages - absent_pages(pages in holes)</code> 。</p>

<h5 id="2-1-1-3-3-managed-pages">2.1.1.3.3. managed_pages</h5>

<p><strong>managed_pages</strong> 是伙伴系统当前管理的页框数，计算方法为 <code>managed_pages = present_pages - reserved_pages</code> 。</p>

<p>因此，内存热插拔系统或者内存的电源管理逻辑可以使用 <code>present_pages - managed_pages</code> 来获得不受管理的页面数。页面分配器和VM扫描器负责计算被管理页面的所有阈值信息。</p>

<h4 id="2-1-1-4-wait-table-xx">2.1.1.4. wait_table_xx</h4>

<p><strong>wait_table</strong> 的相关变量用于追踪等待页面的进程信息，在页面可用时唤醒进程。问题是可能占用大量的空间，特别是同一时刻等待页面的进程很少。因此，我们使用哈希表来代替per-page等待队列。</p>

<p>进程被唤醒时，必须再次确认等待的页面已经可用——由于使用的是哈希表，某一个页面可用时，被唤醒的进程可能有一大堆。</p>

<p><strong>wait_table</strong> 保存等待队列哈希表； <strong>wait_table_hash_nr_entries</strong> 是哈希表的长度，即 <code>1 &lt;&lt; wait_table_bits</code> 。</p>

<h3 id="2-1-2-内存区域的初始化">2.1.2. 内存区域的初始化</h3>

<p><strong>strut zone</strong> 的成员变量的初始化主要由 <code>free_area_init_core</code> 函数完成，函数的调用路径如下：</p>

<ul>
<li><code>start_kernel</code> ,  <em>init/main.c</em>

<ul>
<li><code>setup_arch</code> ,  <em>arch/x86/kernel/setup.c</em></li>
<li><code>x86_init.paging.pagetable_init</code> = <code>native_pagetable_init</code> ,  <em>arch/x86/kernel/x86_init.c</em>

<ul>
<li><code>paging_init</code> ,  <em>arch/x86/mm/init_64.c</em></li>
<li><code>zone_sizes_init</code> ,  <em>arch/x86/mm/init.c</em> , 初始化 max_zone_pfns数组，包含各个zone可以包含的最大的page数

<ul>
<li><code>free_area_init_nodes(max_zone_pfns)</code>,  <em>mm/page_alloc.c</em></li>
<li><code>free_area_init_node</code> ,  <em>mm/page_alloc.c</em>

<ul>
<li><code>free_area_init_core</code> ,  <em>mm/page_alloc.c</em></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>

<p><code>free_area_init_node</code> 主要初始化内存节点的信息，而 <code>free_area_init_core</code> 则初始化节点内的所有内存区域的信息，</p>

<pre><code class="language-C">static void __paginginit free_area_init_core(struct pglist_data *pgdat,
        unsigned long node_start_pfn, unsigned long node_end_pfn,
        unsigned long *zones_size, unsigned long *zholes_size)
{
    enum zone_type j;
    int nid = pgdat-&gt;node_id;
    unsigned long zone_start_pfn = pgdat-&gt;node_start_pfn;
    int ret;
    /*
     resize用来支持内存的热插拔，这个函数在开启
     CONFIG_MEMORY_HOTPLUG时初始化pgdat中的
     node_size_lock自旋锁 */
    pgdat_resize_init(pgdat);
#ifdef CONFIG_NUMA_BALANCING
    /* 和内存负载均衡相关的参数，此处不多介绍 */
    spin_lock_init(&amp;pgdat-&gt;numabalancing_migrate_lock);
    pgdat-&gt;numabalancing_migrate_nr_pages = 0;
    pgdat-&gt;numabalancing_migrate_next_window = jiffies;
#endif
    /*
     初始化两个等待队列：
     kswap_wait用来唤醒kswapd进程执行内存回收操作
     pfmemalloc_wait暂时不清楚用途 */
    init_waitqueue_head(&amp;pgdat-&gt;kswapd_wait);
    init_waitqueue_head(&amp;pgdat-&gt;pfmemalloc_wait);
    /* 和cgroup相关的初始化 */
    pgdat_page_cgroup_init(pgdat);

    /* 初始化pg_data_t中包含的每个zone的信息 */
    for (j = 0; j &lt; MAX_NR_ZONES; j++) {
        struct zone *zone = pgdat-&gt;node_zones + j;
        unsigned long size, realsize, freesize, memmap_pages;

        size = zone_spanned_pages_in_node(nid, j, node_start_pfn,
                          node_end_pfn, zones_size);
        realsize = freesize = size - zone_absent_pages_in_node(nid, j,
                                node_start_pfn,
                                node_end_pfn,
                                zholes_size);

        /*
         * Adjust freesize so that it accounts for how much memory
         * is used by this zone for memmap. This affects the watermark
         * and per-cpu initialisations
         */
        memmap_pages = calc_memmap_size(size, realsize);
        if (freesize &gt;= memmap_pages) {
            freesize -= memmap_pages;
            if (memmap_pages)
                printk(KERN_DEBUG
                       &quot;  %s zone: %lu pages used for memmap\n&quot;,
                       zone_names[j], memmap_pages);
        } else
            printk(KERN_WARNING
                &quot;  %s zone: %lu pages exceeds freesize %lu\n&quot;,
                zone_names[j], memmap_pages, freesize);

        /* Account for reserved pages */
        if (j == 0 &amp;&amp; freesize &gt; dma_reserve) {
            freesize -= dma_reserve;
            printk(KERN_DEBUG &quot;  %s zone: %lu pages reserved\n&quot;,
                    zone_names[0], dma_reserve);
        }

        if (!is_highmem_idx(j))
            nr_kernel_pages += freesize;
        /* Charge for highmem memmap if there are enough kernel pages */
        else if (nr_kernel_pages &gt; memmap_pages * 2)
            nr_kernel_pages -= memmap_pages;
        nr_all_pages += freesize;

        zone-&gt;spanned_pages = size;
        zone-&gt;present_pages = realsize;
        /*
         * Set an approximate value for lowmem here, it will be adjusted
         * when the bootmem allocator frees pages into the buddy system.
         * And all highmem pages will be managed by the buddy system.
         */
        zone-&gt;managed_pages = is_highmem_idx(j) ? realsize : freesize;
#ifdef CONFIG_NUMA
        zone-&gt;node = nid;
        zone-&gt;min_unmapped_pages = (freesize*sysctl_min_unmapped_ratio)
                        / 100;
        zone-&gt;min_slab_pages = (freesize * sysctl_min_slab_ratio) / 100;
#endif
        zone-&gt;name = zone_names[j];
        spin_lock_init(&amp;zone-&gt;lock);
        spin_lock_init(&amp;zone-&gt;lru_lock);
        zone_seqlock_init(zone);
        zone-&gt;zone_pgdat = pgdat;
        /* 初始化per-cpu成员变量pageset */
        zone_pcp_init(zone);

        /* For bootup, initialized properly in watermark setup */
        mod_zone_page_state(zone, NR_ALLOC_BATCH, zone-&gt;managed_pages);
        /* 初始化成员变量lruvec */
        lruvec_init(&amp;zone-&gt;lruvec);
        if (!size)
            continue;

        set_pageblock_order();
        /* sparse模型下为空 */
        setup_usemap(pgdat, zone, zone_start_pfn, size);
        /* 初始化zone的wait_table和free_area域 */
        ret = init_currently_empty_zone(zone, zone_start_pfn,
                        size, MEMMAP_EARLY);
        BUG_ON(ret);
        /* 设置zone内页框对应的struct page信息 */
        memmap_init(size, nid, j, zone_start_pfn);
        zone_start_pfn += size;
    }
}
</code></pre>

<h1 id="3-zone-pcp-init">3. zone_pcp_init</h1>

<p><code>free_area_init_core</code> 还会调用 <code>zone_pcp_init</code> 初始化 <strong>struct zone</strong> 的成员 <strong>struct per_cpu_pageset __percpu *pageset</strong> ，即《深入理解Linux内核》一书中第八章内存管理的“每cpu页框高速缓存”一节。</p>

<p>根据书中所述：</p>

<blockquote>
<p>为了提升系统性能，每个内存管理区定义了一个“每CPU”页框高速缓存。所有“每CPU”页框高速缓存包含一些预先分配的页框，它们用于满足本地CPU发出的单一内存请求。</p>
</blockquote>

<p>这里的“每CPU”页框高速缓存就是 <strong>struct per_cpu_pageset</strong> ，定义在 <em>include/linux/mmzone.h</em> 。书中还说每个 <strong>per_cpu_pageset</strong> 对象都包含两个 <strong>struct per_cpu_pages</strong> 对象，一个热高速缓存，一个冷高速缓存——这个是2.6内核的实现，3.16只包含一个 <strong>per_cpu_pages</strong> 对象。</p>

<p><strong>struct per_cpu_pages</strong> 定义如下：</p>

<pre><code class="language-C">struct per_cpu_pages {
    int count;      /* 高速缓存中页框数 */
    int high;       /* 上界，表示高速缓存用尽 */
    int batch;      /* 添加/移除操作的页框数 */

    /* Lists of pages, one per migrate type stored on the pcp-lists */
    struct list_head lists[MIGRATE_PCPTYPES];
};
</code></pre>

<h2 id="3-1-boot-pageset">3.1. boot_pageset</h2>

<p><code>zone_pcp_init</code> 直接将zone的pageset指向定义在 <em>mm/page_alloc.c</em> 中的 <strong>boot_pageset</strong> 变量，这个变量在 <code>__build_all_zonelists</code> 函数中通过 <code>setup_pageset</code> 初始化：</p>

<pre><code class="language-C">static void setup_pageset(struct per_cpu_pageset *p, unsigned long batch)
{
    pageset_init(p);
    pageset_set_batch(p, batch);
}
</code></pre>

<p>其中 <code>pageset_init</code> 初始化 <strong>struct per_cpu_pageset</strong> 的每个成员； <code>pageset_set_batch</code> 设置per-cpu页框高速缓存的batch为传入的值，即0。</p>

<h2 id="3-2-rmqueue-bulk">3.2. rmqueue_bulk</h2>

<p><code>zone_pcp_init</code> 将zone的pageset指向 <strong>boot_pageset</strong> 后，per-cpu页框高速缓存中没有可用的页。<br />
buddy allocator分配内存页时，会调用 <code>rmqueue_bulk</code> 分配页框到per-cpu页框高速缓存。这个函数在buddy allocator一文中再进行详细说明。</p>

<h1 id="4-free-area的初始化">4. free_area的初始化</h1>

<p>上面的函数建立了zone和zonelist，但是分配内存页真正用到的其实是 <strong>struct zone</strong> 中的 <strong>struct free_area free_area[MAX_ORDER]</strong> 成员，zone中的所有内存会分成 $2^{0}-2^{10}$ 个连续的页框，以解决外碎片的问题。</p>

<h2 id="4-1-init-currently-empty-zone">4.1. init_currently_empty_zone</h2>

<p><code>free_area_init_core</code> 调用 <code>init_currently_empty_zone</code> 函数完成 <strong>free_area</strong> 的初始化，这个函数只是将每种大小的 <strong>free_area</strong> 的数量初始化为零，并且初始化每种 <strong>free_area</strong> 包含的所有 migrate type 的链表。<br />
但是并没有真正建立可以分配内存页的 <strong>free_area</strong> 结构。</p>

<h2 id="4-2-memmap-init-zone">4.2. memmap_init_zone</h2>

<p><code>free_area_init_core</code> 调用的另一个函数 <code>memmap_init</code> ，x86架构下定义为 <code>memmap_init_zone</code> 。<br />
这个函数主要设置zone中每个page的具体信息，即 <strong>struct page</strong> 的各个成员变量。</p>

<pre><code class="language-C">void __meminit memmap_init_zone(unsigned long size, int nid, unsigned long zone,
        unsigned long start_pfn, enum memmap_context context)
{
    struct page *page;
    unsigned long end_pfn = start_pfn + size;
    unsigned long pfn;
    struct zone *z;

    if (highest_memmap_pfn &lt; end_pfn - 1)
        highest_memmap_pfn = end_pfn - 1;

    z = &amp;NODE_DATA(nid)-&gt;node_zones[zone];
    for (pfn = start_pfn; pfn &lt; end_pfn; pfn++) {
        /*
         * There can be holes in boot-time mem_map[]s
         * handed to this function.  They do not
         * exist on hotplugged memory.
         */
        if (context == MEMMAP_EARLY) {
            if (!early_pfn_valid(pfn))
                continue;
            if (!early_pfn_in_nid(pfn, nid))
                continue;
        }
        page = pfn_to_page(pfn);
        /*
         下列操作设置struct page的各个成员：
         flag域的zone，nodeid，memsection，
         _count = -1，
         _mapcount = 1，
         _last_cpuid = 0xff，
         flag域的reserved标志 */
        set_page_links(page, zone, nid, pfn);
        mminit_verify_page_links(page, zone, nid, pfn);
        init_page_count(page);
        page_mapcount_reset(page);
        page_cpupid_reset_last(page);
        SetPageReserved(page);

        if ((z-&gt;zone_start_pfn &lt;= pfn)
            &amp;&amp; (pfn &lt; zone_end_pfn(z))
            &amp;&amp; !(pfn &amp; (pageblock_nr_pages - 1)))
            set_pageblock_migratetype(page, MIGRATE_MOVABLE);

        INIT_LIST_HEAD(&amp;page-&gt;lru);
#ifdef WANT_PAGE_VIRTUAL    //x86 下未定义
        /* The shift won't overflow because ZONE_NORMAL is below 4G. */
        if (!is_highmem_idx(zone))
            set_page_address(page, __va(pfn &lt;&lt; PAGE_SHIFT));
#endif
    }
}
</code></pre>

<h2 id="4-3-free-all-bootmem">4.3. free_all_bootmem</h2>

<p><strong>free_area</strong> 初始化的过程，是在 <code>free_all_bootmem</code> 函数，这个函数由 <em>arch/x86/mm/init_64.c</em> 中的 <code>mem_init</code> 调用。<br />
x86下， <strong>CONFIG_NO_BOOTMEM=y</strong> ，即没有开启bootmem，因此采用 <em>mm/nobootmem.c</em> 中的定义，调用 <code>free_low_memory_core_early</code> 函数完成主要工作：</p>

<pre><code class="language-C">static unsigned long __init free_low_memory_core_early(void)
{
    unsigned long count = 0;
    phys_addr_t start, end;
    u64 i;

    for_each_free_mem_range(i, NUMA_NO_NODE, &amp;start, &amp;end, NULL)
        count += __free_memory_core(start, end);

#ifdef CONFIG_ARCH_DISCARD_MEMBLOCK //x86下默认定义
    {
        phys_addr_t size;

        /* Free memblock.reserved array if it was allocated */
        size = get_allocated_memblock_reserved_regions_info(&amp;start);
        if (size)
            count += __free_memory_core(start, start + size);

        /* Free memblock.memory array if it was allocated */
        size = get_allocated_memblock_memory_regions_info(&amp;start);
        if (size)
            count += __free_memory_core(start, start + size);
    }
#endif

    return count;
}
</code></pre>

<p>函数主要通过 <code>__free_memory_core</code> 释放 <strong>memblock</strong> 中保存的内存块，后者调用 <code>__free_pages_memory</code> ：</p>

<pre><code class="language-C">static void __init __free_pages_memory(unsigned long start, unsigned long end)
{
    int order;

    while (start &lt; end) {
        /*
         MAX_ORDER = 11，__ffs返回start中最高位的索引，
         因此，start越大，order可能越大，但是最大不会
         超过10 */
        order = min(MAX_ORDER - 1UL, __ffs(start));
        /* 将order限制在合法的范围内 */
        while (start + (1UL &lt;&lt; order) &gt; end)
            order--;

        __free_pages_bootmem(pfn_to_page(start), order);

        start += (1UL &lt;&lt; order);
    }
}
</code></pre>

<p><code>__free_pages_memory</code>最终会调用 <em>mm/page_alloc.c</em> 中的 <code>__free_pages_bootmem</code> ，传入起始页面和释放的order：</p>

<pre><code class="language-C">void __init __free_pages_bootmem(struct page *page, unsigned int order)
{
    unsigned int nr_pages = 1 &lt;&lt; order;
    struct page *p = page;
    unsigned int loop;

    prefetchw(p);
    for (loop = 0; loop &lt; (nr_pages - 1); loop++, p++) {
        prefetchw(p + 1);
        __ClearPageReserved(p);
        set_page_count(p, 0);
    }
    __ClearPageReserved(p);
    set_page_count(p, 0);

    page_zone(page)-&gt;managed_pages += nr_pages;
    set_page_refcounted(page);
    __free_pages(page, order);
}
</code></pre>

<p><code>__free_pages_bootmem</code> 清除之前的reserved标志，先将 <strong>_count</strong> 设置为0，之后再设置为1，然后调用 <code>__free_pages</code>，将page释放到buddy系统。</p>

<p><code>__free_pages</code> 是伙伴系统释放内存页的函数，放在下一篇buddy allocator进行说明。</p>

<h1 id="5-总结">5. 总结</h1>

<p>至此，伙伴系统分配页面所需的内存信息建立完成：zone，zonelist，以及每个zone的free_area信息。<br />
buddy allocator的具体执行流程，在下一篇文章介绍。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">Globs Guo</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2019-10-24
        
    </span>
  </p>
  
  
</div>
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">Reward</label>
  <div class="qr-code">
    
    <label class="qr-code-image" for="reward">
        <img class="image" src="/img/reward/wechat.jpg">
        <span>wechat</span>
      </label>
    <label class="qr-code-image" for="reward">
        <img class="image" src="/img/reward/alipay.jpg">
        <span>alipay</span>
      </label>
  </div>
</div><footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kernel-sources/">kernel-sources</a>
          <a href="/tags/memory/">memory</a>
          <a href="/tags/zonelist/">zonelist</a>
          <a href="/tags/node_data/">NODE_DATA</a>
          <a href="/tags/buddy-allocator/">buddy-allocator</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/mm-buddy_allocator_page_allocation-1/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">mm-buddy_allocator分配页框(上)</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/mm-slab_initialization/">
            <span class="next-text nav-default">mm-slab初始化</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  
    <script src="https://utteranc.es/client.js"
            repo="GlobsGuo/utterancesRepo"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/utterance">comments powered by utterances.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="sendtomedivh@126.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/globsguo" class="iconfont icon-github" title="github"></a>
  <a href="https://globsguo.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Globs Guo</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"  integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>








</body>
</html>
