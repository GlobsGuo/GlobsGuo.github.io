<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Memory Management Initialization - Globs&#39; Catchall</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Globs Guo" /><meta name="description" content="本文从Linux内核的内存管理关键的数据结构出发，结合内核源码中的注释，说明Linux的内存管理用到的数据结构的初始化流程。本文以x86-6" />






<meta name="generator" content="Hugo 0.58.3 with theme even" />


<link rel="canonical" href="https://globsguo.github.io/post/memory_management/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Memory Management Initialization" />
<meta property="og:description" content="本文从Linux内核的内存管理关键的数据结构出发，结合内核源码中的注释，说明Linux的内存管理用到的数据结构的初始化流程。本文以x86-6" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://globsguo.github.io/post/memory_management/" />
<meta property="article:published_time" content="2019-10-12T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-10-12T00:00:00+00:00" />
<meta itemprop="name" content="Memory Management Initialization">
<meta itemprop="description" content="本文从Linux内核的内存管理关键的数据结构出发，结合内核源码中的注释，说明Linux的内存管理用到的数据结构的初始化流程。本文以x86-6">


<meta itemprop="datePublished" content="2019-10-12T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-10-12T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="11281">



<meta itemprop="keywords" content="kernel sources,memory model,vmemmap,NODE_DATA,zonelist,mem_section," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Memory Management Initialization"/>
<meta name="twitter:description" content="本文从Linux内核的内存管理关键的数据结构出发，结合内核源码中的注释，说明Linux的内存管理用到的数据结构的初始化流程。本文以x86-6"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Globs&#39; Catchall</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Globs&#39; Catchall</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Memory Management Initialization</h1>

      <div class="post-meta">
        <span class="post-time"> 2019-10-12 100:100 </span>
        
          <span class="more-meta"> 11281 words </span>
          <span class="more-meta"> 23 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li><a href="#1-memory-model">1. Memory Model</a>
<ul>
<li><a href="#1-1-flat-memory-model">1.1. Flat Memory Model</a></li>
<li><a href="#1-2-discontiguous-memory-model">1.2. Discontiguous Memory Model</a>
<ul>
<li><a href="#1-2-1-pfn-to-page">1.2.1. __pfn_to_page</a></li>
</ul></li>
<li><a href="#1-3-sparse-memory-model">1.3. Sparse Memory Model</a>
<ul>
<li><a href="#1-3-1-page-to-pfn">1.3.1. __page_to_pfn</a></li>
<li><a href="#1-3-2-pfn-to-page">1.3.2. __pfn_to_page</a></li>
<li><a href="#1-3-3-vmemmap">1.3.3. VMEMMAP</a></li>
</ul></li>
</ul></li>
<li><a href="#2-mem-section">2. mem_section</a>
<ul>
<li><a href="#2-1-sparse-init">2.1. sparse_init</a>
<ul>
<li><a href="#2-1-1-sparse-early-usemaps-alloc-node">2.1.1. sparse_early_usemaps_alloc_node</a></li>
<li><a href="#2-1-2-sparse-early-mem-maps-alloc-node">2.1.2. sparse_early_mem_maps_alloc_node</a>
<ul>
<li><a href="#2-1-2-1-non-vmemmap">2.1.2.1. non-vmemmap</a></li>
<li><a href="#2-1-2-2-vmemmap">2.1.2.2. vmemmap</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#3-内存节点">3. 内存节点</a>
<ul>
<li><a href="#3-1-stuct-pglist-data-node-data">3.1. stuct pglist_data *node_data[]</a></li>
<li><a href="#3-2-node-data-的初始化">3.2.  <strong>node_data</strong> 的初始化</a>
<ul>
<li><a href="#3-2-1-setup-node-data">3.2.1. setup_node_data</a></li>
<li><a href="#3-2-2-free-area-init-node">3.2.2. free_area_init_node</a></li>
</ul></li>
<li><a href="#3-3-zonelist的初始化">3.3. zonelist的初始化</a>
<ul>
<li><a href="#3-3-1-build-zonelists">3.3.1. build_zonelists</a></li>
<li><a href="#3-3-2-build-zonelist-cache">3.3.2. build_zonelist_cache</a>
<ul>
<li><a href="#3-3-2-1-zlcache的说明">3.3.2.1. zlcache的说明</a></li>
<li><a href="#3-3-2-2-zlcache的初始化">3.3.2.2. zlcache的初始化</a></li>
</ul></li>
<li><a href="#3-3-3-zonelist的额外说明">3.3.3. zonelist的额外说明</a></li>
</ul></li>
</ul></li>
<li><a href="#4-内存区域">4. 内存区域</a>
<ul>
<li><a href="#4-1-struct-zone">4.1. struct zone</a>
<ul>
<li><a href="#4-1-1-struct-zone的成员变量">4.1.1. struct zone的成员变量</a>
<ul>
<li><a href="#4-1-1-1-watermark">4.1.1.1. watermark</a>
<ul>
<li><a href="#4-1-1-1-1-wmark-low">4.1.1.1.1. WMARK_LOW</a></li>
<li><a href="#4-1-1-1-2-wmark-min">4.1.1.1.2. WMARK_MIN</a></li>
<li><a href="#4-1-1-1-3-wmark-high">4.1.1.1.3. WMARK_HIGH</a></li>
</ul></li>
<li><a href="#4-1-1-2-lowmem-reserve">4.1.1.2. lowmem_reserve</a></li>
<li><a href="#4-1-1-3-xx-pages">4.1.1.3. xx_pages</a>
<ul>
<li><a href="#4-1-1-3-1-spanned-pages">4.1.1.3.1. spanned_pages</a></li>
<li><a href="#4-1-1-3-2-present-pages">4.1.1.3.2. present_pages</a></li>
<li><a href="#4-1-1-3-3-managed-pages">4.1.1.3.3. managed_pages</a></li>
</ul></li>
<li><a href="#4-1-1-4-wait-table-xx">4.1.1.4. wait_table_xx</a></li>
</ul></li>
<li><a href="#4-1-2-内存区域的初始化">4.1.2. 内存区域的初始化</a></li>
</ul></li>
</ul></li>
<li><a href="#5-总结">5. 总结</a></li>
</ul>
</nav>
  </div>
</div>
    <div class="post-content">
      

<p>本文从Linux内核的内存管理关键的数据结构出发，结合内核源码中的注释，说明Linux的内存管理用到的数据结构的初始化流程。本文以x86-64架构为例，假设系统类型为NUMA，sparse memory model。</p>

<h1 id="1-memory-model">1. Memory Model</h1>

<p>内存模型一部分内容主要来自<a href="http://www.wowotech.net/memory_management/memory_model.html">网上</a>， <em>Documentation</em> 中没有找到相关的内容。</p>

<p>内存模型是从CPU的角度看，系统中物理内存的分布情况；在Linux内核中，使用何种方式来管理这些物理内存。</p>

<p>Linux支持三种内存模型，flat memory，discontiguous memory和sparse memory。</p>

<p>本文假设所有的CPU共享同一段物理地址空间。</p>

<h2 id="1-1-flat-memory-model">1.1. Flat Memory Model</h2>

<p>从系统的任意一个CPU来看，访问物理内存的时候，物理地址空间是连续的，没有空洞的地址空间，这种计算机系统的内存模型就是flat memory model。</p>

<p>这种情况下，节点数据 <strong>pg_data_t</strong> 只有一个，物理页框号和 <strong>struct page \ *mem_map</strong> 可以通过一个偏移量互相转化。将 <strong>mem_map</strong> 放在内存的直接映射区域，操作系统就不需要再为内存建立页表。</p>

<pre><code class="language-C">// include/asm-generic/memory_model.h
#define __pfn_to_page(pfn)    (mem_map + ((pfn) - ARCH_PFN_OFFSET))
#define __page_to_pfn(page)    ((unsigned long)((page) - mem_map) + ARCH_PFN_OFFSET)
</code></pre>

<h2 id="1-2-discontiguous-memory-model">1.2. Discontiguous Memory Model</h2>

<p>如果物理内存的地址空间有空洞，这种内存模型就是discontiguous memory model。</p>

<p>这种情况下，节点数据 <strong>pg_data_t</strong> 有多个，每个节点管理的物理内存都保存在 <strong>pg_data_t</strong> 中的 <strong>node_mem_map</strong> (类似于flat模型中的 <strong>mem_map</strong> )成员中。从物理页框号转化为 <strong>struct page</strong> 需要先从PFN中得到节点ID，然后找到对应的 <strong>pg_data_t</strong> ，就可以像flat模型一样获得 <strong>struct page</strong> 数组。</p>

<pre><code class="language-C">// include/asm-generic/memory_model.h
#define __pfn_to_page(pfn)          \
({  unsigned long __pfn = (pfn);        \
    unsigned long __nid = arch_pfn_to_nid(__pfn);  \
    NODE_DATA(__nid)-&gt;node_mem_map + arch_local_page_offset(__pfn, __nid);\
})

#define __page_to_pfn(pg)                       \
({  const struct page *__pg = (pg);                 \
    struct pglist_data *__pgdat = NODE_DATA(page_to_nid(__pg)); \
    (unsigned long)(__pg - __pgdat-&gt;node_mem_map) +         \
     __pgdat-&gt;node_start_pfn;                   \
})
</code></pre>

<h3 id="1-2-1-pfn-to-page">1.2.1. __pfn_to_page</h3>

<p>x86下，只有32位(选择32位内核才会出现flat memory model)系统 <code>arch_pfn_to_nid</code> 有定义：</p>

<pre><code class="language-C">static inline int pfn_to_nid(unsigned long pfn)
{
#ifdef CONFIG_NUMA
    return((int) physnode_map[(pfn) / PAGES_PER_SECTION]);
#else
    return 0;
#endif
}
</code></pre>

<p>本文主要着眼于64位系统，32位的有关内容不再详细介绍。</p>

<h2 id="1-3-sparse-memory-model">1.3. Sparse Memory Model</h2>

<p>sparse模型用来解决内存的热插拔可能导致的内存节点内的 <strong>mem_map</strong> 不连续的问题。这种模型将连续的地址空间按照section(x86_64 NUMA架构下为128M)分段，每一个section都是hotplug的。</p>

<p>整个物理内存的地址空间通过指针 <strong>struct mem_section *</strong> 数组来描述，每个 <strong>mem_section *</strong> 指向一个page，page中包含若干个 <strong>struct mem_section</strong> 对象，每个对象描述一个section。</p>

<p>每一个section内部，内存地址都是连续的。因此， <strong>mem_map</strong> 的page数组依赖于section结构。</p>

<pre><code class="language-C">#define __page_to_pfn(pg)                   \
({  const struct page *__pg = (pg);             \
    int __sec = page_to_section(__pg);          \
    (unsigned long)(__pg - __section_mem_map_addr(__nr_to_section(__sec))); \
})

#define __pfn_to_page(pfn)              \
({  unsigned long __pfn = (pfn);            \
    struct mem_section *__sec = __pfn_to_section(__pfn);    \
    __section_mem_map_addr(__sec) + __pfn;      \
})
</code></pre>

<p>如果开启了 <strong>CONFIG_SPARSEMEM_VMEMMAP</strong> 选项(默认开启)，PFN和 <strong>struct page *</strong> 之间的转化十分简单：</p>

<pre><code class="language-C">/* memmap is virtually contiguous.  */
#define __pfn_to_page(pfn)  (vmemmap + (pfn))
#define __page_to_pfn(page) (unsigned long)((page) - vmemmap)
</code></pre>

<h3 id="1-3-1-page-to-pfn">1.3.1. __page_to_pfn</h3>

<p>如果开启了 <strong>CONFIG_SPARSEMEM</strong> ，但是没有开启 <strong>CONFIG_SPARSEMEM_VMEMMAP</strong> ，就会开启 <strong>SECTION_IN_PAGE_FLAGS</strong> 选项，即在页表中包含section信息，据此实现 <code>page_to_section</code> 。</p>

<p><code>__nr_to_section</code> 的实现也很简单，但是需要了解变量 <strong>mem_section</strong> 的定义：</p>

<pre><code class="language-C">#ifdef CONFIG_SPARSEMEM_EXTREME
struct mem_section *mem_section[NR_SECTION_ROOTS]
    ____cacheline_internodealigned_in_smp;
#else
struct mem_section mem_section[NR_SECTION_ROOTS][SECTIONS_PER_ROOT]
    ____cacheline_internodealigned_in_smp;
#endif
EXPORT_SYMBOL(mem_section);
</code></pre>

<p>取得section的index后，进行二维数组的访问操作即可获得对应的section结构体：</p>

<pre><code class="language-C">static inline struct mem_section *__nr_to_section(unsigned long nr)
{
    if (!mem_section[SECTION_NR_TO_ROOT(nr)])
        return NULL;
    return &amp;mem_section[SECTION_NR_TO_ROOT(nr)][nr &amp; SECTION_ROOT_MASK];
}
</code></pre>

<p>从section中获取对应的 <strong>struct page *</strong> 的首地址后，用要查找的<strong>struct page *</strong> 减去section的首地址，即可获得对应的PFN。</p>

<p>内核代码中有 <code>__page_to_pfn</code> 函数的注释如下：</p>

<blockquote>
<p>setion&rsquo;s mem_map is encoded to reflect its start_pfn.</p>

<p>section[i].section_mem_map = mem_map&rsquo;s address = start_pfn.</p>
</blockquote>

<h3 id="1-3-2-pfn-to-page">1.3.2. __pfn_to_page</h3>

<p>同理，由PFN可以得到所在的section的index，然后通过 <code>__nr_to_section</code> 获得section，再根据section中保存的 <strong>struct page *</strong> 的起始地址，获取PFN对应的 <strong>struct page *</strong>。</p>

<h3 id="1-3-3-vmemmap">1.3.3. VMEMMAP</h3>

<p>如果开启 <strong>CONFIG_SPARSEMEM_VMEMMAP</strong> ，所有的 <strong>struct page *</strong> 都保存在连续的地址空间中，起始地址为 <strong>VMEMMAP_START</strong> ，x86架构定义在 <em>arch/x86/include/asm/pgtable_64_types.h</em> ，为0xffffea0000000000UL。</p>

<h1 id="2-mem-section">2. mem_section</h1>

<p>使用sparse内存模型的NUMA系统，将所有的物理内存分成内存段，即mem_section。 <em>mm/sparse.c</em> 中定义的<strong>struct mem_section *mem_section[NR_SECTION_ROOTS]</strong> 变量(x86下默认开启 <strong>CONFIG_SPARSEMEM_EXTREME</strong> )，包含系统中所有的内存段。</p>

<p>根据定义可知， <strong>mem_section</strong> 变量是长度为 <strong>NR_SECTION_ROOTS</strong> 指针数组，而 <strong>NR_SECTION_ROOTS = 2K</strong> ，所以 <strong>mem_section</strong> 占用<strong>16B * 2K = 32KB</strong>的空间。</p>

<p>这个数组是静态的，无论对应的内存段是否存在。</p>

<p><strong>mem_section</strong> 的初始化过程由 <code>sparse_init</code> 完成，函数的调用路径如下：</p>

<ul>
<li><code>start_kernel</code> ,  <em>init/main.c</em>

<ul>
<li><code>setup_arch</code> ,  <em>arch/x86/kernel/setup.c</em></li>
<li><code>x86_init.paging.pagetable_init</code> = <code>native_pagetable_init</code> ,  <em>arch/x86/kernel/x86_init.c</em>

<ul>
<li><code>paging_init</code> ,  <em>arch/x86/mm/init_64.c</em></li>
<li><code>sparse_init</code> ,  <em>arch/x86/mm/sparse.c</em></li>
<li><code>zone_sizes_init</code> ,  <em>arch/x86/mm/init.c</em> , 初始化 max_zone_pfns数组，包含各个zone可以包含的最大的page数

<ul>
<li><code>free_area_init_nodes(max_zone_pfns)</code>,  <em>mm/page_alloc.c</em></li>
<li><code>free_area_init_node</code> ,  <em>mm/page_alloc.c</em></li>
</ul></li>
</ul></li>
</ul></li>
</ul>

<p>这里先说明 <em>arch/x86/mm/init_64.c</em> 中的 <code>paging_init</code> 函数：</p>

<pre><code class="language-C">void __init paging_init(void)
{
    sparse_memory_present_with_active_regions(MAX_NUMNODES);
    sparse_init();

    /*
     * clear the default setting with node 0
     * note: don't use nodes_clear here, that is really clearing when
     *   numa support is not compiled in, and later node_set_state
     *   will not set it back.
     */  
    node_clear_state(0, N_MEMORY);
    if (N_MEMORY != N_NORMAL_MEMORY)
        node_clear_state(0, N_NORMAL_MEMORY);

    zone_sizes_init();
}
</code></pre>

<p><code>paging_init</code> 首先调用 <code>sparse_memory_present_with_active_region</code> 将系统内所有内存节点的物理页框通过 <code>memroy_present</code> 保存到 <strong>mem_section</strong> ，并且初始化 <strong>mem_section</strong> 数组的成员大小为 <strong>SECTION_PER_ROOT * sizeof(struct mem_section)</strong>( <strong>CONFIG_SPARSEMEM_EXTREME</strong> 的情况)；然后调用 <code>sparse_init</code> 重新设置 <strong>section_mem_map</strong> 成员；最后通过 <code>zone_sizes_init</code> 初始化内存区域。</p>

<p>需要说明的是， <code>memory_presents</code> 函数不但将节点包含的物理页框添加到 <strong>mem_section</strong> ，还会设置每个 <strong>mem_section</strong> 的 <strong>section_mem_map</strong> 成员为 <strong>(所属的节点ID &lt;&lt; SECTION_NID_SHIFT | SECTION_MARKED_PRESENT)</strong> 。</p>

<h2 id="2-1-sparse-init">2.1. sparse_init</h2>

<p><code>sparse_init</code> 主要设置 <strong>mem_section</strong> 的 <strong>section_mem_map</strong> 成员，将 <code>sparse_memory_present_with_active_regions</code> 函数保存的内容替换为对应的PFN，以便第一部分内存模型中介绍的 <code>pfn_to_page</code> 和 <code>page_to_pfn</code> 工作正常。</p>

<pre><code class="language-C">void __init sparse_init(void)
{
    unsigned long pnum;
    struct page *map;
    unsigned long *usemap;
    unsigned long **usemap_map;
    int size;
/* 默认情况下为真 */
#ifdef CONFIG_SPARSEMEM_ALLOC_MEM_MAP_TOGETHER
    int size2;
    struct page **map_map;
#endif

    /* see include/linux/mmzone.h 'struct mem_section' definition */
    BUILD_BUG_ON(!is_power_of_2(sizeof(struct mem_section)));

    /* Setup pageblock_order for HUGETLB_PAGE_SIZE_VARIABLE */
    set_pageblock_order();

    /*
     * map is using big page (aka 2M in x86 64 bit)
     * usemap is less one page (aka 24 bytes)
     * so alloc 2M (with 2M align) and 24 bytes in turn will
     * make next 2M slip to one more 2M later.
     * then in big system, the memory will have a lot of holes...
     * here try to allocate 2M pages continuously.
     *
     * powerpc need to call sparse_init_one_section right after each
     * sparse_early_mem_map_alloc, so allocate usemap_map at first.
     */
    /*# size = 8B * 512K = 4MB */
    /* 为每一个section分配一个指针所需的空间 */
    size = sizeof(unsigned long *) * NR_MEM_SECTIONS;
    /* 上面这段注释的意思是说如果轮流分配usemap和map的内存
       会留下许多内存空洞。
       memblock_virt_alloc从memblock中分配内存空间 */
    usemap_map = memblock_virt_alloc(size, 0);
    if (!usemap_map)
        panic(&quot;can not allocate usemap_map\n&quot;);
    /*sparse_early_usemaps_alloc_node从给定的*/
    alloc_usemap_and_memmap(sparse_early_usemaps_alloc_node,
                            (void *)usemap_map);

#ifdef CONFIG_SPARSEMEM_ALLOC_MEM_MAP_TOGETHER
    size2 = sizeof(struct page *) * NR_MEM_SECTIONS;
    map_map = memblock_virt_alloc(size2, 0);
    if (!map_map)
        panic(&quot;can not allocate map_map\n&quot;);
    alloc_usemap_and_memmap(sparse_early_mem_maps_alloc_node,
                            (void *)map_map);
#endif

    for (pnum = 0; pnum &lt; NR_MEM_SECTIONS; pnum++) {
        if (!present_section_nr(pnum))
            continue;

        usemap = usemap_map[pnum];
        if (!usemap)
            continue;

#ifdef CONFIG_SPARSEMEM_ALLOC_MEM_MAP_TOGETHER
        map = map_map[pnum];
#else
        map = sparse_early_mem_map_alloc(pnum);
#endif
        if (!map)
            continue;

        sparse_init_one_section(__nr_to_section(pnum), pnum, map,
                                usemap);
    }

    vmemmap_populate_print_last();

#ifdef CONFIG_SPARSEMEM_ALLOC_MEM_MAP_TOGETHER
    memblock_free_early(__pa(map_map), size2);
#endif
    memblock_free_early(__pa(usemap_map), size);
}
</code></pre>

<p><code>sparse_init</code> 函数的主要工作由 <code>alloc_usemap_and_memmap</code> 完成，后者负责遍历 <strong>mem_section</strong> 数组，实际的工作由参数 <code>alloc_func</code> 完成：</p>

<pre><code class="language-C">static void __init alloc_usemap_and_memmap(void (*alloc_func)
                    (void *, unsigned long, unsigned long,
                    unsigned long, int), void *data)
{
    unsigned long pnum;
    unsigned long map_count;
    int nodeid_begin = 0;
    unsigned long pnum_begin = 0;

    /* 遍历mem_section数组，寻找第一个标记为present的section */
    for (pnum = 0; pnum &lt; NR_MEM_SECTIONS; pnum++) {
        struct mem_section *ms;

        /* 略过没有标记为present的section */
        if (!present_section_nr(pnum))
            continue;
        /* 找到了标记为present的section */
        /* 根据section的index获取对应的section指针 */
        ms = __nr_to_section(pnum);
        /* 现在，section_mem_map中保存着section所属的节点ID */
        nodeid_begin = sparse_early_nid(ms);
        pnum_begin = pnum;
        break;
    }
    map_count = 1;
    /* 从present的section开始，为属于同一个节点的所有section
       调用alloc_func */
    for (pnum = pnum_begin + 1; pnum &lt; NR_MEM_SECTIONS; pnum++) {
        struct mem_section *ms;
        int nodeid;

        /* 跳过没有present的section */
        if (!present_section_nr(pnum))
            continue;
        ms = __nr_to_section(pnum);
        nodeid = sparse_early_nid(ms);
        /* 当前section和起始section属于相同的节点，增加map count */
        if (nodeid == nodeid_begin) {
            /*# increase the map count */
            map_count++;
            continue;
        }
        /* ok, we need to take cake of from pnum_begin to pnum - 1*/
        alloc_func(data, pnum_begin, pnum,
                        map_count, nodeid_begin);
        /* new start, update count etc*/
        nodeid_begin = nodeid;
        pnum_begin = pnum;
        map_count = 1;
    }
    /* ok, last chunk */
    alloc_func(data, pnum_begin, NR_MEM_SECTIONS,
                        map_count, nodeid_begin);
}
</code></pre>

<p><code>sparse_init</code> 函数先后两次调用 <code>alloc_usemap_and_memmap</code> 函数，传入的 <strong>alloc_func</strong> 分别为 <code>sparse_early_usemaps_alloc_node</code> 和 <code>sparse_early_mem_maps_alloc_node</code> ， <strong>data</strong> 分别为保存 <strong>unsigned long *</strong> 对象的 <strong>usemap_map</strong>  和 <strong>struct page *</strong> 对象的 <strong>map_map</strong> 。</p>

<h3 id="2-1-1-sparse-early-usemaps-alloc-node">2.1.1. sparse_early_usemaps_alloc_node</h3>

<p>分配函数为 <code>sparse_early_usemaps_alloc_node</code> 时， <strong>data</strong> 参数为长度为 <strong>NR_MEM_SECTIONS</strong> 的 <strong>unsigned long *</strong> 数组 <strong>usemap_map</strong> 。</p>

<pre><code class="language-C">static void __init sparse_early_usemaps_alloc_node(void *data,
                 unsigned long pnum_begin,
                 unsigned long pnum_end,
                 unsigned long usemap_count, int nodeid)
{
    void *usemap;
    unsigned long pnum;
    unsigned long **usemap_map = (unsigned long **)data;
    /*  */
    int size = usemap_size();
    /* 从指定节点的memblock中分配所需的内存空间
       usemap_count为存在的section的数量 */
    usemap = sparse_early_usemaps_alloc_pgdat_section(NODE_DATA(nodeid),
                              size * usemap_count);
    if (!usemap) {
        printk(KERN_WARNING &quot;%s: allocation failed\n&quot;, __func__);
        return;
    }

    for (pnum = pnum_begin; pnum &lt; pnum_end; pnum++) {
        /* 跳过不存在的section */
        if (!present_section_nr(pnum))
            continue;
        /* 设置section对应的usemap_map数组元素指向分配的 */
        usemap_map[pnum] = usemap;
        usemap += size;
        check_usemap_section_nr(nodeid, usemap_map[pnum]);
    }
}
</code></pre>

<h3 id="2-1-2-sparse-early-mem-maps-alloc-node">2.1.2. sparse_early_mem_maps_alloc_node</h3>

<p>分配函数为 <code>sparse_early_mem_maps_alloc_node</code> 时， <strong>data</strong> 参数为长度为 <strong>NR_MEM_SECTIONS</strong> 的<strong>struct page *</strong> 数组 <strong>map_map</strong> 。</p>

<pre><code class="language-C">static void __init sparse_early_mem_maps_alloc_node(void *data,
                 unsigned long pnum_begin,
                 unsigned long pnum_end,
                 unsigned long map_count, int nodeid)
{
    struct page **map_map = (struct page **)data;
    sparse_mem_maps_populate_node(map_map, pnum_begin, pnum_end,
                     map_count, nodeid);
}
</code></pre>

<p>和SPARSEMEM相关的还有一个配置项，即前面说到的 <strong>CONFIG_SPARSEMEM_VMEMMAP</strong> ，开启此选项，系统中所有的<strong>struct page *</strong> 对象保存在连续的内存地址空间中。对应的， <code>sparse_mem_maps_populate_node</code> 函数有两个定义。</p>

<h4 id="2-1-2-1-non-vmemmap">2.1.2.1. non-vmemmap</h4>

<p>non-vmemmap情况下 <code>sparse_mem_maps_populate_node</code> 函数定义在 <em>mm/sparse.c</em> 中：</p>

<pre><code class="language-C">void __init sparse_mem_maps_populate_node(struct page **map_map,
                      unsigned long pnum_begin,
                      unsigned long pnum_end,
                      unsigned long map_count, int nodeid)
{
    void *map;
    unsigned long pnum;
    /* size的为描述每个section包含的页框所需的内存大小 */
    unsigned long size = sizeof(struct page) * PAGES_PER_SECTION;
    /* x86下alloc_remap函数返回NULL */
    map = alloc_remap(nodeid, size * map_count);
    if (map) {
        for (pnum = pnum_begin; pnum &lt; pnum_end; pnum++) {
            if (!present_section_nr(pnum))
                continue;
            map_map[pnum] = map;
            map += size;
        }
        return;
    }

    size = PAGE_ALIGN(size);
    /* 从memblock中分配所需的内存，大小为描述节点内所有的
       section包含的页框所需的内存 */
    map = memblock_virt_alloc_try_nid(size * map_count,
                      PAGE_SIZE, __pa(MAX_DMA_ADDRESS),
                      BOOTMEM_ALLOC_ACCESSIBLE, nodeid);
    if (map) {
        for (pnum = pnum_begin; pnum &lt; pnum_end; pnum++) {
            /* 跳过不存在的section */
            if (!present_section_nr(pnum))
                continue;
            /* 将map_map中对应的元素指向该section包含的所有页框
               的struct page的地址，即section内第一个页面对应的
               struct page的地址*/
            map_map[pnum] = map;
            map += size;
        }
        return;
    }

    /* fallback */
    /* fallback只是再次执行上述相同的操作 */
    for (pnum = pnum_begin; pnum &lt; pnum_end; pnum++) {
        struct mem_section *ms;

        if (!present_section_nr(pnum))
            continue;
        map_map[pnum] = sparse_mem_map_populate(pnum, nodeid);
        if (map_map[pnum])
            continue;
        ms = __nr_to_section(pnum);
        printk(KERN_ERR &quot;%s: sparsemem memory map backing failed &quot;
            &quot;some memory will not be available.\n&quot;, __func__);
        ms-&gt;section_mem_map = 0;
    }
}
</code></pre>

<p>可以看到，non-vmemmap情况下，每次调用 <code>sparse_mem_maps_populate_node</code> 函数只是从memblock中分配所需的内存空间，分配的内存空间很有可能不连续。</p>

<h4 id="2-1-2-2-vmemmap">2.1.2.2. vmemmap</h4>

<p>配置vmemmap的情况下， <code>sparse_mem_maps_populate_node</code> 定义在*mm/sprase-vmemmap.c*中， <strong>QUESTION</strong></p>

<pre><code class="language-C">void __init sparse_mem_maps_populate_node(struct page **map_map,
                      unsigned long pnum_begin,
                      unsigned long pnum_end,
                      unsigned long map_count, int nodeid)
{
    unsigned long pnum;
    unsigned long size = sizeof(struct page) * PAGES_PER_SECTION;
    void *vmemmap_buf_start;
    /* PMD_SIZE = 2MB，对齐到PMD_SIZE， 这里有个疑问，为什么
       要对齐到2MB */
    size = ALIGN(size, PMD_SIZE);
    /* 从指定节点的memblock分配所需的内存空间 */
    vmemmap_buf_start = __earlyonly_bootmem_alloc(nodeid, size * map_count,
             PMD_SIZE, __pa(MAX_DMA_ADDRESS));
    /* 内存分配成功，保存起始地址和结束地址。
       vmemmap_buf用于分配下列操作中建立页表所需的内存空间，在
       页表建立完成后释放没有使用的缓冲区 */
    if (vmemmap_buf_start) {
        vmemmap_buf = vmemmap_buf_start;
        vmemmap_buf_end = vmemmap_buf_start + size * map_count;
    }

    for (pnum = pnum_begin; pnum &lt; pnum_end; pnum++) {
        struct mem_section *ms;
        /* 跳过不存在的section */
        if (!present_section_nr(pnum))
            continue;
        /* 为section中包含的所有页框对应的struct page建立页表。
           建立页表时会使用第一部分中定义的pfn_to_page宏，从而
           将每一个section内的所有pfn对应的struct page *都保存
           在连续的虚拟地址空间中，并且返回section中首个pfn对应
           的struct page *，保存在map_map中 */
        map_map[pnum] = sparse_mem_map_populate(pnum, nodeid);
        if (map_map[pnum])
            continue;
        ms = __nr_to_section(pnum);
        printk(KERN_ERR &quot;%s: sparsemem memory map backing failed &quot;
            &quot;some memory will not be available.\n&quot;, __func__);
        ms-&gt;section_mem_map = 0;
    }

    /* 释放vmemmap缓冲区 */
    if (vmemmap_buf_start) {
        /* need to free left buf */
        memblock_free_early(__pa(vmemmap_buf),
                    vmemmap_buf_end - vmemmap_buf);
        vmemmap_buf = NULL;
        vmemmap_buf_end = NULL;
    }
}
</code></pre>

<p>至此，系统中内存段的初始化完成，可以通过pfn_to_page和page_to_pfn将 <strong>PFN</strong> 和 <strong>struct page *</strong> 相互转化。</p>

<h1 id="3-内存节点">3. 内存节点</h1>

<p>内存节点是内核管理物理内存的最上层抽象。对于NUMA系统，至少包含一个节点0。每个节点都有一个 <strong>struct pglist_data</strong> 对象指针，包含该节点的所有物理内存信息。</p>

<h2 id="3-1-stuct-pglist-data-node-data">3.1. stuct pglist_data *node_data[]</h2>

<p>x86架构下，变量 <strong>struct pglist_data *node_data[]</strong> 保存系统中的所有节点信息，定义在 <em>arch/x86/mm/numa.c</em> 中。</p>

<pre><code class="language-c">typedef struct pglist_data {
    /* 节点包含的所有zone信息 */
    struct zone node_zones[MAX_NR_ZONES];
    struct zonelist node_zonelists[MAX_ZONELISTS];
    int nr_zones;
#ifdef CONFIG_MEMORY_HOTPLUG
    /*
     * Must be held any time you expect node_start_pfn, node_present_pages
     * or node_spanned_pages stay constant.  Holding this will also
     * guarantee that any pfn_valid() stays that way.
     *
     * pgdat_resize_lock() and pgdat_resize_unlock() are provided to
     * manipulate node_size_lock without checking for CONFIG_MEMORY_HOTPLUG.
     *
     * Nests above zone-&gt;lock and zone-&gt;span_seqlock
     */
    spinlock_t node_size_lock;
#endif
    unsigned long node_start_pfn;
    unsigned long node_present_pages; /* total number of physical pages */
    unsigned long node_spanned_pages; /* total size of physical page
                         range, including holes */
    int node_id;
    wait_queue_head_t kswapd_wait;
    wait_queue_head_t pfmemalloc_wait;
    struct task_struct *kswapd; /* Protected by
                       mem_hotplug_begin/end() */
    int kswapd_max_order;
    enum zone_type classzone_idx;
#ifdef CONFIG_NUMA_BALANCING
    /* Lock serializing the migrate rate limiting window */
    spinlock_t numabalancing_migrate_lock;

    /* Rate limiting time interval */
    unsigned long numabalancing_migrate_next_window;

    /* Number of pages migrated during the rate limiting time interval */
    unsigned long numabalancing_migrate_nr_pages;
#endif
} pg_data_t;

</code></pre>

<h2 id="3-2-node-data-的初始化">3.2.  <strong>node_data</strong> 的初始化</h2>

<p><em>arch/x86/include/asm/mmzone_64.h</em> 中定义了访问 <strong>node_data</strong> 变量的宏<code>#define NODE_DATA(nid) (node_data[nid])</code>，内核中的代码大多使用这个宏访问 <strong>node_data</strong> 变量。</p>

<h3 id="3-2-1-setup-node-data">3.2.1. setup_node_data</h3>

<p>函数 <code>setup_node_data</code> 负责分配 <strong>node_data</strong> 变量，进行一些成员的简单初始化，函数的调用路径如下：</p>

<ul>
<li><code>start_kernel</code> ,  <em>init/main.c</em>

<ul>
<li><code>setup_arch</code> ,  <em>arch/x86/kernel/setup.c</em></li>
<li><code>initmem_init</code> ,  <em>arch/x86/mm/numa_64.c</em>

<ul>
<li><code>x86_numa_init</code> ,  <em>arch/x86/mm/numa.c</em></li>
<li><code>numa_init</code> ,  <em>arch/x86/mm/numa.c</em>

<ul>
<li><code>x86_acpi_numa_init</code> ,  <em>arch/x86/mm/srat.c</em></li>
<li><code>acpi_numa_init</code> ,  <em>drivers/acpi/numa.c</em></li>
<li><code>numa_register_memblks</code> ,  <em>arch/x86/mm/numa.c</em></li>
<li><code>setup_node_data</code> ,  <em>arch/x86/mm/numa.c</em></li>
</ul></li>
</ul></li>
</ul></li>
</ul>

<p>需要说明的是，实际测试时，根据boot log， <code>x86_numa_init</code> 的执行过程如下：</p>

<pre><code class="language-C">void __init x86_numa_init(void)
{
    if (!numa_off) {      // 通常为false，即默认启用NUMA
#ifdef CONFIG_ACPI_NUMA   // x86-64通常为true
        /* numa_init函数执行时，会调用x86_acpi_numa_init函数，
           主要是转化ACPI的SRAT和SLIT的操作。从boot log来看，
           函数返回值为负数，导致numa_init函数退出 */
        if (!numa_init(x86_acpi_numa_init))
            return;
#endif
#ifdef CONFIG_AMD_NUMA  // x86-64为true
        /* amd_numa_init函数从北桥的PCI配置空间获取
           NUMA信息，如果返回值为负数 */
        if (!numa_init(amd_numa_init))
            return;
#endif
    }
    /* 函数执行dummy_numa_init */
    numa_init(dummy_numa_init);
}
</code></pre>

<p>也就是说，默认情况下，x86架构开启NUMA配置， <code>x86_numa_init</code> 函数首先执行 <code>x86_acpi_numa_init</code> 函数，尝试从ACPI的SRAT中获取NUMA信息，成功的话函数直接退出；否则再调用 <code>amd_numa_init</code> ，从北桥的PCI配置空间获取NUMA信息，成功的话直接退出；否则再调用 <code>dummy_numa_init</code> ，直接将<strong>0 - max_pfn</strong>范围的物理页框作为节点0(这个范围内可能有空洞)。</p>

<p>不论是哪种方式，成功获取到NUMA信息后，都会将其添加到 <strong>numa_meminofo</strong> 变量。这个变量由 <code>numa_init</code> 调用函数 <code>numa_register_memblks</code> 时作为参数传递，添加到 <strong>memblock</strong> 变量，同时传递给 <code>setup_node_data</code> 函数，即每个节点的起始页框索引。</p>

<pre><code class="language-C">/* Initialize NODE_DATA for a node on the local memory */
static void __init setup_node_data(int nid, u64 start, u64 end)
{
    const size_t nd_size = roundup(sizeof(pg_data_t), PAGE_SIZE);
    u64 nd_pa;
    void *nd;
    int tnid;

    /*
     * Don't confuse VM with a node that doesn't have the
     * minimum amount of memory:
     */
    if (end &amp;&amp; (end - start) &lt; NODE_MIN_SIZE)
        return;

    /* ZONE_ALIGN = 8MB */
    start = roundup(start, ZONE_ALIGN);

    printk(KERN_INFO &quot;Initmem setup node %d [mem %#010Lx-%#010Lx]\n&quot;,
           nid, start, end - 1);

    /*
     * Allocate node data.  Try node-local memory and then any node.
     * Never allocate in DMA zone.
     */
    nd_pa = memblock_alloc_nid(nd_size, SMP_CACHE_BYTES, nid);
    if (!nd_pa) {
        nd_pa = __memblock_alloc_base(nd_size, SMP_CACHE_BYTES,
                          MEMBLOCK_ALLOC_ACCESSIBLE);
        if (!nd_pa) {
            pr_err(&quot;Cannot find %zu bytes in node %d\n&quot;,
                   nd_size, nid);
            return;
        }
    }
    nd = __va(nd_pa);

    /* report and initialize */
    printk(KERN_INFO &quot;  NODE_DATA [mem %#010Lx-%#010Lx]\n&quot;,
           nd_pa, nd_pa + nd_size - 1);
    tnid = early_pfn_to_nid(nd_pa &gt;&gt; PAGE_SHIFT);
    /* 分配node_data的节点和当前内存节点不一致 */
    if (tnid != nid)
        printk(KERN_INFO &quot;    NODE_DATA(%d) on node %d\n&quot;, nid, tnid);

    node_data[nid] = nd;
    memset(NODE_DATA(nid), 0, sizeof(pg_data_t));
    NODE_DATA(nid)-&gt;node_id = nid;
    NODE_DATA(nid)-&gt;node_start_pfn = start &gt;&gt; PAGE_SHIFT;
    NODE_DATA(nid)-&gt;node_spanned_pages = (end - start) &gt;&gt; PAGE_SHIFT;

    node_set_online(nid);
}
</code></pre>

<h3 id="3-2-2-free-area-init-node">3.2.2. free_area_init_node</h3>

<p><code>setup_node_data</code> 函数只会初始化 <strong>pg_data_t</strong> 的部分成员变量(节点信息，起始页框信息)，其余成员变量的初始化在函数 <code>free_area_init_node</code> 完成，两个函数的调用路径的先后顺序如下：</p>

<ul>
<li><code>start_kernel</code> ,  <em>init/main.c</em>

<ul>
<li><code>setup_arch</code> ,  <em>arch/x86/kernel/setup.c</em></li>
<li><code>initmem_init</code> ,  <em>arch/x86/mm/numa_64.c</em>

<ul>
<li><code>x86_numa_init</code> ,  <em>arch/x86/mm/numa.c</em></li>
<li><code>numa_init</code> ,  <em>arch/x86/mm/numa.c</em>

<ul>
<li><code>x86_acpi_numa_init</code> ,  <em>arch/x86/mm/srat.c</em></li>
<li><code>acpi_numa_init</code> ,  <em>drivers/acpi/numa.c</em></li>
<li><code>numa_register_memblks</code> ,  <em>arch/x86/mm/numa.c</em></li>
<li><code>setup_node_data</code> ,  <em>arch/x86/mm/numa.c</em></li>
</ul></li>
</ul></li>
<li><code>x86_init.paging.pagetable_init</code> = <code>native_pagetable_init</code> ,  <em>arch/x86/kernel/x86_init.c</em>

<ul>
<li><code>paging_init</code> ,  <em>arch/x86/mm/init_64.c</em></li>
<li><code>zone_sizes_init</code> ,  <em>arch/x86/mm/init.c</em> , 初始化 max_zone_pfns数组，包含各个zone可以包含的最大的page数

<ul>
<li><code>free_area_init_nodes(max_zone_pfns)</code>,  <em>mm/page_alloc.c</em></li>
<li><code>free_area_init_node</code> ,  <em>mm/page_alloc.c</em></li>
</ul></li>
</ul></li>
<li><code>build_all_zonelists</code> ,  <em>mm/page_alloc.c</em></li>
<li><code>page_alloc_init</code> ,  <em>mm/page_alloc.c</em></li>
<li><code>mm_init</code> ,  <em>init/main.c</em></li>
<li><code>kmem_cache_init</code> ,  <em>mm/slub.c</em></li>
</ul></li>
</ul>

<p><code>setup_node_data</code> 使用的NUMA信息来自ACPI表或者BIOS-e820，可能包含空洞，PFN的范围不准确； <code>free_area_init_node</code> 使用的内存信息来自 <strong>struct memblock memblock</strong> 变量，用 <strong>memblock</strong> 的信息对NUMA信息进一步修正( <strong>memblock</strong> 定义在 <em>mm/memblock.c</em> 中，保存始化阶段通过 <code>memblock_reserve</code> 、 <code>memblock_set_node</code> 函数保留的内存信息。)：</p>

<pre><code class="language-C">/* 执行上面的函数路径时，
   @zones_size = NULL
   @zholes_size = NULL */
void __paginginit free_area_init_node(int nid, unsigned long *zones_size,
        unsigned long node_start_pfn, unsigned long *zholes_size)
{
    /* 获取指定nid的pg_data_t指针 */
    pg_data_t *pgdat = NODE_DATA(nid);
    unsigned long start_pfn = 0;
    unsigned long end_pfn = 0;

    /* pg_data_t should be reset to zero when it's allocated */
    /* struct pglist_data *node_data[MAX_NUMNODES] */
    WARN_ON(pgdat-&gt;nr_zones || pgdat-&gt;classzone_idx);

    pgdat-&gt;node_id = nid;
    pgdat-&gt;node_start_pfn = node_start_pfn;
#ifdef CONFIG_HAVE_MEMBLOCK_NODE_MAP    //true
    /* 根据struct memblock memblock提供的信息获取给定
       node的起始页框。如果节点没有可用内存，起始
       和结束页框号都设置为0，并输出警告信息 */
    get_pfn_range_for_nid(nid, &amp;start_pfn, &amp;end_pfn);
#endif
    /* 计算node中的所有页面数
       pgdata-&gt;node_spanned_pages = 页面总数
       pgdata-&gt;node_present_pages = 总数 - hole */
    calculate_node_totalpages(pgdat, start_pfn, end_pfn,
                  zones_size, zholes_size);
    /* x86_64下函数为空 */
    alloc_node_mem_map(pgdat);
#ifdef CONFIG_FLAT_NODE_MEM_MAP     //false
    printk(KERN_DEBUG &quot;free_area_init_node: node %d, pgdat %08lx, node_mem_map %08lx\n&quot;,
        nid, (unsigned long)pgdat,
        (unsigned long)pgdat-&gt;node_mem_map);
#endif
    /* 初始化pgdat中的成员变量，以及包含的每个zone的信息
       @zones_size = NULL
       @zholes_size = NULL */
    free_area_init_core(pgdat, start_pfn, end_pfn,
                zones_size, zholes_size);
}
</code></pre>

<p>至此，变量 <strong>node_data</strong> 初始化完毕，包含的节点信息供后续的内存初始化操作使用。</p>

<h2 id="3-3-zonelist的初始化">3.3. zonelist的初始化</h2>

<p><code>start_kernel</code> 函数会调用 <code>build_all_zonelists</code> 初始化内存区域表，即 <strong>pg_data_t</strong> 的 <strong>node_zonelists</strong> 成员。</p>

<p><code>build_all_zonelists</code> 会调用 <code>__build_all_zonelists</code> ，后者分别调用 <code>build_zonelists</code> 和 <code>build_zonelist_cache</code> 完成zonelist的初始化：</p>

<pre><code class="language-C">static int __build_all_zonelists(void *data)
{
    int nid;
    int cpu;
    pg_data_t *self = data;

#ifdef CONFIG_NUMA
    /* node_load数组记录每个内存节点的负载情况 */
    memset(node_load, 0, sizeof(node_load));
#endif
    /* self指针在响应内存的热插拔时为pg_data_t，
       否则为NULL。这个分支用来执行内存的热插拔操作 */
    if (self &amp;&amp; !node_online(self-&gt;node_id)) {
        build_zonelists(self);
        build_zonelist_cache(self);
    }
    /* 为每个在线的节点创建zonelist，以及zlcache */
    for_each_online_node(nid) {
        pg_data_t *pgdat = NODE_DATA(nid);

        build_zonelists(pgdat);
        build_zonelist_cache(pgdat);
    }
     /*
     * Initialize the boot_pagesets that are going to be used
     * for bootstrapping processors. The real pagesets for
     * each zone will be allocated later when the per cpu
     * allocator is available.
     *
     * boot_pagesets are used also for bootstrapping offline
     * cpus if the system is already booted because the pagesets
     * are needed to initialize allocators on a specific cpu too.
     * F.e. the percpu allocator needs the page allocator which
     * needs the percpu allocator in order to allocate its pagesets
     * (a chicken-egg dilemma).
     */
    for_each_possible_cpu(cpu) {
        setup_pageset(&amp;per_cpu(boot_pageset, cpu), 0);

#ifdef CONFIG_HAVE_MEMORYLESS_NODES   // x86默认为false
        /*
         * We now know the &quot;local memory node&quot; for each node--
         * i.e., the node of the first zone in the generic zonelist.
         * Set up numa_mem percpu variable for on-line cpus.  During
         * boot, only the boot cpu should be on-line;  we'll init the
         * secondary cpus' numa_mem as they come on-line.  During
         * node/memory hotplug, we'll fixup all on-line cpus.
         */
        if (cpu_online(cpu))
            set_cpu_numa_mem(cpu, local_memory_node(cpu_to_node(cpu)));
#endif
    }

    return 0;
}
</code></pre>

<p><strong>struct zonelist</strong> 结构如下，</p>

<pre><code class="language-C">struct zonelist {
    struct zonelist_cache *zlcache_ptr;          // NULL or &amp;zlcache
    struct zoneref _zonerefs[MAX_ZONES_PER_ZONELIST + 1];
#ifdef CONFIG_NUMA
    struct zonelist_cache zlcache;               // optional ...
#endif
};
</code></pre>

<p><strong>MAX_ZONES_PER_ZONELIST</strong> 为系统中的节点数和zone类型数的乘积，假如系统中共有2各节点，zone有3种类型(DMA，DMA32，NORMAL)，则  <strong>_zonerefs</strong>  的长度为6 + 1 = 7。数组的最后一个元素总是设置为空，作为结束标志。</p>

<h3 id="3-3-1-build-zonelists">3.3.1. build_zonelists</h3>

<p><code>build_zonelists</code> 函数完成  <strong>pg_data_t</strong>  成员 <strong>struct zonelist node_zonelists[MAX_ZONELISTS]</strong> 的初始化工作。zonelist是页面请求操作的对象，其中第一个zone是首选目标，其余的zone是备选项，按照优先级降序排列。</p>

<p>NUMA系统中， <strong>MAX_ZONELISTS</strong> 为2，因为我们需要支持  <strong>__GFP_THISNODE</strong>  选项：</p>

<ul>
<li>node_zonelists[0]<br />
带有备选node的zonelist</li>
<li>node_zonelists[1]<br />
没有备选node的zonelist</li>
</ul>

<p>zonelist的备选node通过函数 <code>find_next_best_node</code> 确定：备选node不能已经包含在zonelist中，应该是距离当前节点次近的节点，不属于任何CPU的节点更佳——这些节点没有分配内存的压力。距离根据距离数组计算——数组中包含系统中所有节点间的距离。</p>

<pre><code class="language-C">static void build_zonelists(pg_data_t *pgdat)
{
    int j, node, load;
    enum zone_type i;
    nodemask_t used_mask;
    int local_node, prev_node;
    struct zonelist *zonelist;
    int order = current_zonelist_order;

    /* initialize zonelists */
    for (i = 0; i &lt; MAX_ZONELISTS; i++) {
        zonelist = pgdat-&gt;node_zonelists + i;
        /* 为了加速zonelist的读取操作，_zonerefs包含
           正在读取的zone的索引，避免访问大的数据结构。*/
        zonelist-&gt;_zonerefs[0].zone = NULL;
        zonelist-&gt;_zonerefs[0].zone_idx = 0;
    }

    /* NUMA-aware ordering of nodes */
    local_node = pgdat-&gt;node_id;
    load = nr_online_nodes;
    prev_node = local_node;
    nodes_clear(used_mask);
    /* 代码中此变量的注释写道：
       创建zonelist时会按照zone type从高到低的顺序
       排列，出现高位内存即normal内存消耗殆尽，而DMA
       内存还没有使用的情况，导致页面的分配操作被较远
       的节点响应。
       结合下面的代码，这个数组用来记录创建zonelist时
       每个node出现的先后顺序，按照和当前节点的距离
       降序排列。 */
    memset(node_order, 0, sizeof(node_order));
    j = 0;

    /* 寻找可以作为备选节点的node */
    while ((node = find_next_best_node(local_node, &amp;used_mask)) &gt;= 0) {
        /*
         * We don't want to pressure a particular node.
         * So adding penalty to the first node in same
         * distance group to make it round-robin.
         */
        if (node_distance(local_node, node) !=
            node_distance(local_node, prev_node))
            node_load[node] = load;

        prev_node = node;
        /* load供find_next_best_node函数寻找下一个备选节点
           时作为参考依据 */
        load--;
        if (order == ZONELIST_ORDER_NODE)
            /* zonelist首先按照节点的距离排序，然后按照节点内
               zone类型排序。这种情况能够保证最大局部性：normal
               内存消耗完之后，继续消耗本节点内的DMA内存。最后
               才会转向其他的节点，但是可能会耗尽DMA内存。 */
            build_zonelists_in_node_order(pgdat, node);
        else
            node_order[j++] = node; /* remember order */
    }
    /* 根据node_order数组按照距离由小到大添加所有节点
       同一类型的zone，这种方式可以避免耗尽DMA内存 */
    if (order == ZONELIST_ORDER_ZONE) {
        /* calculate node order -- i.e., DMA last! */
        build_zonelists_in_zone_order(pgdat, j);
    }
    /* 创建支持GFP_THISNODE的zonelist，即没有备选节点的
       node_zonelists[1]。这种情况下，系统为非NUMA，只
       需要将节点0添加到zonelist两种即可 */
    build_thisnode_zonelists(pgdat);
}

</code></pre>

<p>可以看到，创建zonelist时，有两种策略，一种为了保证最大程度的局部性，即 <code>build_zonelists_in_node_order</code> ；一种为了避免DMA内存被耗尽，即 <code>build_zonelists_in_zone_order</code> 。两种策略可以通过grub参数“numa_zonelist_order”设置，也可以通过sysctl设置。</p>

<p><code>build_zonelists_in_node_order</code> 找到传入的 <strong>pgdata</strong> 的<strong>node_zonelists[0]</strong> 中第一个没有设置的  <strong>_zonerefs</strong>  ，即  <strong>_zonerefs</strong>  中的最后一个元素，然后将 <strong>zonelist</strong> 中包含的所有zone按照类型从高到低的顺序添加到  <strong>_zonerefs</strong>  中：</p>

<pre><code class="language-C">static void build_zonelists_in_node_order(pg_data_t *pgdat, int node)
{
    int j;
    struct zonelist *zonelist;

    zonelist = &amp;pgdat-&gt;node_zonelists[0];
    /* 获取_zonerefs中最后一个元素的索引j */
    for (j = 0; zonelist-&gt;_zonerefs[j].zone != NULL; j++)
        ;
    /* 将zonelist中的所有zone按照类型由高到低的顺序添加到
       _zonerefs中从j开始的位置 */
    j = build_zonelists_node(NODE_DATA(node), zonelist, j);
    /* 设置_zonerefs中的最后一个元素为空，作为结束标志 */
    zonelist-&gt;_zonerefs[j].zone = NULL;
    zonelist-&gt;_zonerefs[j].zone_idx = 0;
}
</code></pre>

<p><code>build_zonelists_in_zone_order</code> 则根据 <strong>node_order</strong> 数组中按照距当前节点的距离保存的内存节点先将同一类型的每个节点的所有zone添加，然后添加其他类型的zone，按照类型从高到低的顺序：</p>

<pre><code class="language-C">static void build_zonelists_in_zone_order(pg_data_t *pgdat, int nr_nodes)
{
    int pos, j, node;
    int zone_type;      /* needs to be signed */
    struct zone *z;
    struct zonelist *zonelist;

    zonelist = &amp;pgdat-&gt;node_zonelists[0];
    pos = 0;
    /* 按照zone类型从高到底的顺序 */
    for (zone_type = MAX_NR_ZONES - 1; zone_type &gt;= 0; zone_type--) {
        for (j = 0; j &lt; nr_nodes; j++) {
            node = node_order[j];
            z = &amp;NODE_DATA(node)-&gt;node_zones[zone_type];
            /* zone有效 */
            if (populated_zone(z)) {
                zoneref_set_zone(z,
                    &amp;zonelist-&gt;_zonerefs[pos++]);
                check_highest_zone(zone_type);
            }
        }
    }
    /* 设置最后一个_zonerefs为空，作为结束标志 */
    zonelist-&gt;_zonerefs[pos].zone = NULL;
    zonelist-&gt;_zonerefs[pos].zone_idx = 0;
}
</code></pre>

<p>假设系统中有两个内存节点0和1，每个节点都有ZONE_DMA，ZONE_DMA32，ZONE_NORMAL三种类型的区域，则NODE_DATA(0)的<strong>zonelist-&gt;_zonerefs</strong>在两种情况下初始化后分别为：</p>

<ul>
<li>node order<br />
{ ZONE_NORMAL-0, ZONE_DMA32-0, ZONE_DMA-0，<br />
ZONE_NORMAL-1, ZONE_DMA32-1, ZONE_DMA-1 }</li>
<li>zone order<br />
{ ZONE_NORMAL-0, ZONE_NORMAL-1, ZONE_DMA32-0,<br />
ZONE_DMA32-1, ZONE_DMA-0, ZONE_DMA-1 }</li>
</ul>

<h3 id="3-3-2-build-zonelist-cache">3.3.2. build_zonelist_cache</h3>

<h4 id="3-3-2-1-zlcache的说明">3.3.2.1. zlcache的说明</h4>

<p><code>build_zonelist_cache</code> 初始化 <strong>struct zonelist</strong> 中的剩余两个成员变量： <strong>zlcache_ptr</strong> 和 <strong>zlcache</strong> 。</p>

<p><strong>struct zonelist_cache</strong> 缓存每个zonelist的关键信息，以便在<code>get_page_from_freelist()</code>函数中扫描空闲页面时减小高速缓存的footprint。</p>

<pre><code class="language-C">struct zonelist_cache {
    unsigned short z_to_n[MAX_ZONES_PER_ZONELIST];      /* zone-&gt;nid */
    DECLARE_BITMAP(fullzones, MAX_ZONES_PER_ZONELIST);  /* zone full? */
    unsigned long last_full_zap;        /* when last zap'd (jiffies) */
};
</code></pre>

<p>位图 <strong>fullzones</strong> 追踪上次zero&rsquo;d fullzones之后，zonelist中缺少空闲内存的zone信息。</p>

<p>数组<strong>z_to_n[]</strong>将zonelist中的每个zone映射到所属的节点的ID，以便快速确认该节点是否包含在当前进程的 <strong>mems_allowed</strong> 中。</p>

<p><strong>fullzones</strong> 和 <strong>z_to_n[]</strong> 都是和zonelist一一对应，通过zonelist的  <strong>_zonerefs</strong> 提供的偏移量进行索引。</p>

<p><code>get_page_from_freelist()</code>函数执行两次扫描。第一次扫描时，跳过设置了 <strong>fullzones</strong> 中对应位的zone，以及对应的节点没有包含在<strong>current-&gt;mems_allowed</strong>中的zone。第二次扫描时，跳过 <strong>zonelist_cache</strong> ，保证查看了每个zone。</p>

<p>每一秒钟执行一次zero out(zap) fullzones的操作， <strong>last_full_zap</strong> 保存上一次zap操作的时间。这种机制可以减少zone刚刚进入低内存状态，不停地检测zone是否有空闲内存所花费的时间。</p>

<h4 id="3-3-2-2-zlcache的初始化">3.3.2.2. zlcache的初始化</h4>

<p>函数 <code>build_zonelist_cache</code> 完成zlcache的初始化，</p>

<pre><code class="language-C">static void build_zonelist_cache(pg_data_t *pgdat)
{
    struct zonelist *zonelist;
    struct zonelist_cache *zlc;
    struct zoneref *z;
    /* 只需要初始化node_zonelists[0]，即有备选节点的
       zonelist；没有备选节点的zonelist不需要zlcache
       来减小zonelist的footprint */
    zonelist = &amp;pgdat-&gt;node_zonelists[0];
    /* zlcache_ptr指向自身的zlcache即可 */
    zonelist-&gt;zlcache_ptr = zlc = &amp;zonelist-&gt;zlcache;
    /* 初始化fullzones位图 */
    bitmap_zero(zlc-&gt;fullzones, MAX_ZONES_PER_ZONELIST);
    /* 将zonelist中的每个zone所属的节点信息保存在z_to_n[] */
    for (z = zonelist-&gt;_zonerefs; z-&gt;zone; z++)
        zlc-&gt;z_to_n[z - zonelist-&gt;_zonerefs] = zonelist_node_idx(z);
}
</code></pre>

<h3 id="3-3-3-zonelist的额外说明">3.3.3. zonelist的额外说明</h3>

<p><strong>struct zonelist_cache</strong> 的成员属于 <strong>struct zonelist</strong> 。但是， <strong>MPOL_BIND</strong> 内存策略的zonelist结构体长度不同，通常更短—— <strong>MPOL_BIND</strong> 策略不需要 <strong>zonelist_cache</strong> 成员，因此我们将固定长度的成员放在zonelist结构体的起始位置，以 <strong>zonelist_cache</strong> 结尾。</p>

<p><strong>zonelist_cache</strong> 这个可选的成员变量通过 <strong>zlcache_ptr</strong> 指针定位，在 <strong>MPOL_BIND</strong> 的情况下指针为NULL。</p>

<p>由此， <strong>strut zonelist</strong> 有两种形式：</p>

<ol>
<li>完整的，固定长度的版本</li>
<li>针对 <strong>MPOL_BIND</strong> 内存策略的版本( <strong>zlcache_ptr</strong> 为空)</li>
</ol>

<p>虽然存在多个CPU同时修改 <strong>zonelist_cache</strong> 的 <strong>fullzones</strong> 和 <strong>last_full_zap</strong> 的情况，我们没有加锁——这只是提示信息，如果这些信息有误，只不过会影响分配器的运行速度，但是不会影响分配器的功能。</p>

<h1 id="4-内存区域">4. 内存区域</h1>

<p>根据物理内存的使用方式，内核将物理内存分为多个内存区域(zone)，每个zone用 <strong>struct zone</strong> 来描述。以x86_64架构为例，内核包括ZONE_DMA，ZONE_DMA32，ZONE_NORMAL，ZONE_MOVABLE四种。</p>

<p>因为系统中的DMA设备寻址范围小于16MB，因此需要ZONE_DMA；有的设备只能寻址小于4GB的地址，需要ZONE_DMA32。</p>

<h2 id="4-1-struct-zone">4.1. struct zone</h2>

<p>Linux内核用 <strong>struct zone</strong> 描述内存区域：</p>

<pre><code class="language-C">struct zone {
    unsigned long watermark[NR_WMARK];
    long lowmem_reserve[MAX_NR_ZONES];

#ifdef CONFIG_NUMA
    int node;  /* zone所属的内存节点 */
#endif
    unsigned int inactive_ratio;

    struct pglist_data *zone_pgdat;  /* zone所属的pg_data_t */
    struct per_cpu_pageset __percpu *pageset;
    unsigned long dirty_balance_reserve;
#ifdef CONFIG_NUMA
    /*
     * zone reclaim becomes active if more unmapped pages exist.
     */
    unsigned long       min_unmapped_pages;
    unsigned long       min_slab_pages;
#endif /* CONFIG_NUMA */
    unsigned long       zone_start_pfn; /* zone的起始PFN */

    unsigned long       managed_pages;
    unsigned long       spanned_pages;
    unsigned long       present_pages;

    const char      *name;  /* zone的名称 */
    int         nr_migrate_reserve_block;

    wait_queue_head_t   *wait_table;
    unsigned long       wait_table_hash_nr_entries;
    unsigned long       wait_table_bits;

    ZONE_PADDING(_pad1_)

    /* Write-intensive fields used from the page allocator */
    spinlock_t      lock;

    /* free areas of different sizes */
    struct free_area    free_area[MAX_ORDER];

    /* zone flags, see below */
    unsigned long       flags;

    ZONE_PADDING(_pad2_)
    /* Fields commonly accessed by the page reclaim scanner */
    spinlock_t      lru_lock;
    struct lruvec       lruvec;

    /* Evictions &amp; activations on the inactive file list */
    atomic_long_t       inactive_age;

    /*
     * When free pages are below this point, additional steps are taken
     * when reading the number of free pages to avoid per-cpu counter
     * drift allowing watermarks to be breached
     */
    unsigned long percpu_drift_mark;

    ZONE_PADDING(_pad3_)
    /* Zone statistics */
    atomic_long_t       vm_stat[NR_VM_ZONE_STAT_ITEMS];
};
</code></pre>

<h3 id="4-1-1-struct-zone的成员变量">4.1.1. struct zone的成员变量</h3>

<h4 id="4-1-1-1-watermark">4.1.1.1. watermark</h4>

<p>watermark数组长度为3，三个元素分别是WMARK_MIN，WMARK_LOW，WMARK_HIGH。</p>

<p>watermark的描述来自 <strong>undering the linux virtual memory manager</strong> 一书：</p>

<p>可用的内存少于LOW值， <strong>kswapd</strong> 程序就会被唤醒，执行页面释放操作。如果压力很大，进程会同步的释放内存，即direct-reclaim路径。</p>

<p>每一个区域都有一个watermark数组，追踪区域的内存压力。MIN值在内存初始化时通过函数<code>free_area_init_core()</code>计算，通常是ZoneSizeInPages/128。</p>

<h5 id="4-1-1-1-1-wmark-low">4.1.1.1.1. WMARK_LOW</h5>

<p>区域的空闲页面数到达LOW时，伙伴分配器会唤醒 <strong>kswapd</strong> ，开始释放页面。LOW的默认值时MIN的两倍。</p>

<h5 id="4-1-1-1-2-wmark-min">4.1.1.1.2. WMARK_MIN</h5>

<p>到达MIN时，分配器会以同步的方式执行 <strong>kswapd</strong> 操作，被称作*direct-reclaim*路径。</p>

<h5 id="4-1-1-1-3-wmark-high">4.1.1.1.3. WMARK_HIGH</h5>

<p><strong>kswapd</strong> 唤醒之后，直到空闲页面的数量到达HIGH，内存区域才会被视为balanced，此时 <strong>kswapd</strong> 回到休眠状态。HIGH的默认值为MIN的三倍。</p>

<h4 id="4-1-1-2-lowmem-reserve">4.1.1.2. lowmem_reserve</h4>

<p>内核中的注释如下：</p>

<blockquote>
<p>我们不知道分配出去的内存最终是否会被释放，为了避免浪费数GB的内存，我们必须保留lower zone的内存，否则就有在lower zone出现OOM的风险，尽管在higher zone可能有大量可用的内存。</p>

<p>这个数组在运行时会随着 <strong>sysctl_lowmem_reserve_ratio</strong> 的变化而变化。</p>
</blockquote>

<p>根据之前的说明，较高区域的内存通常较大，较低区域的内存通常较小。这个数组用来限制每个内存区域应该保留的内存页的数量，避免在较低内存区域出现OOM的情况。</p>

<h4 id="4-1-1-3-xx-pages">4.1.1.3. xx_pages</h4>

<h5 id="4-1-1-3-1-spanned-pages">4.1.1.3.1. spanned_pages</h5>

<p><strong>spanned_pages</strong> 包含空洞，计算方法为<code>spanned_pages = zone_end_pfn - zone_start_pfn</code>。</p>

<h5 id="4-1-1-3-2-present-pages">4.1.1.3.2. present_pages</h5>

<p><strong>present_pages</strong> 是区域包含的物理页框数，不包含空洞，计算方法为<code>present_pages = spanned_pages - absent_pages(pages in holes)</code>。</p>

<h5 id="4-1-1-3-3-managed-pages">4.1.1.3.3. managed_pages</h5>

<p><strong>managed_pages</strong> 是伙伴系统当前管理的页框数，计算方法为<code>managed_pages = present_pages - reserved_pages</code>。</p>

<p>因此，内存热插拔系统或者内存的电源管理逻辑可以使用<code>present_pages - managed_pages</code>来获得不受管理的页面数。页面分配器和VM扫描器负责计算被管理页面的所有阈值信息。</p>

<h4 id="4-1-1-4-wait-table-xx">4.1.1.4. wait_table_xx</h4>

<p><strong>wait_table</strong> 的相关变量用于追踪等待页面的进程信息，在页面可用时唤醒进程。问题是可能占用大量的空间，特别是同一时刻等待页面的进程很少。因此，我们使用哈希表来代替per-page等待队列。</p>

<p>进程被唤醒时，必须再次确认等待的页面已经可用——由于使用的是哈希表，某一个页面可用时，被唤醒的进程可能有一大堆。</p>

<p><strong>wait_table</strong> 保存等待队列哈希表； <strong>wait_table_hash_nr_entries</strong> 是哈希表的长度，即<code>1 &lt;&lt; wait_table_bits</code>。</p>

<h3 id="4-1-2-内存区域的初始化">4.1.2. 内存区域的初始化</h3>

<p><strong>strut zone</strong> 的成员变量的初始化主要由 <code>free_area_init_core</code> 函数完成，函数的调用路径如下：</p>

<ul>
<li><code>start_kernel</code> ,  <em>init/main.c</em>

<ul>
<li><code>setup_arch</code> ,  <em>arch/x86/kernel/setup.c</em></li>
<li><code>x86_init.paging.pagetable_init</code> = <code>native_pagetable_init</code> ,  <em>arch/x86/kernel/x86_init.c</em>

<ul>
<li><code>paging_init</code> ,  <em>arch/x86/mm/init_64.c</em></li>
<li><code>zone_sizes_init</code> ,  <em>arch/x86/mm/init.c</em> , 初始化 max_zone_pfns数组，包含各个zone可以包含的最大的page数

<ul>
<li><code>free_area_init_nodes(max_zone_pfns)</code>,  <em>mm/page_alloc.c</em></li>
<li><code>free_area_init_node</code> ,  <em>mm/page_alloc.c</em>

<ul>
<li><code>free_area_init_core</code> ,  <em>mm/page_alloc.c</em></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>

<p>根据代码中的注释，函数包括下列步骤：
&gt; 建立zone数据结构：
&gt;
&gt; - 将所有页面标记为reserved
&gt; - 将所有的内存队列标记为空
&gt; - 清除内存位图</p>

<pre><code class="language-C">static void __paginginit free_area_init_core(struct pglist_data *pgdat,
        unsigned long node_start_pfn, unsigned long node_end_pfn,
        unsigned long *zones_size, unsigned long *zholes_size)
{
    enum zone_type j;
    int nid = pgdat-&gt;node_id;
    unsigned long zone_start_pfn = pgdat-&gt;node_start_pfn;
    int ret;
    /* resize用来支持内存的热插拔，这个函数在开启
       CONFIG_MEMORY_HOTPLUG时初始化pgdat中的
       node_size_lock自旋锁 */
    pgdat_resize_init(pgdat);
#ifdef CONFIG_NUMA_BALANCING
    /* 和内存负载均衡相关的参数，此处不多介绍 */
    spin_lock_init(&amp;pgdat-&gt;numabalancing_migrate_lock);
    pgdat-&gt;numabalancing_migrate_nr_pages = 0;
    pgdat-&gt;numabalancing_migrate_next_window = jiffies;
#endif
    /* 初始化两个等待队列
       kswap_wait用来唤醒kswapd进程执行内存回收操作
       pfmemalloc_wait暂时不清楚用途 */
    init_waitqueue_head(&amp;pgdat-&gt;kswapd_wait);
    init_waitqueue_head(&amp;pgdat-&gt;pfmemalloc_wait);
    /* 和cgroup相关的初始化 */
    pgdat_page_cgroup_init(pgdat);

    /* 初始化pg_data_t中包含的每个zone的信息 */
    for (j = 0; j &lt; MAX_NR_ZONES; j++) {
        struct zone *zone = pgdat-&gt;node_zones + j;
        unsigned long size, realsize, freesize, memmap_pages;

        size = zone_spanned_pages_in_node(nid, j, node_start_pfn,
                          node_end_pfn, zones_size);
        realsize = freesize = size - zone_absent_pages_in_node(nid, j,
                                node_start_pfn,
                                node_end_pfn,
                                zholes_size);

        /*
         * Adjust freesize so that it accounts for how much memory
         * is used by this zone for memmap. This affects the watermark
         * and per-cpu initialisations
         */
        memmap_pages = calc_memmap_size(size, realsize);
        if (freesize &gt;= memmap_pages) {
            freesize -= memmap_pages;
            if (memmap_pages)
                printk(KERN_DEBUG
                       &quot;  %s zone: %lu pages used for memmap\n&quot;,
                       zone_names[j], memmap_pages);
        } else
            printk(KERN_WARNING
                &quot;  %s zone: %lu pages exceeds freesize %lu\n&quot;,
                zone_names[j], memmap_pages, freesize);

        /* Account for reserved pages */
        if (j == 0 &amp;&amp; freesize &gt; dma_reserve) {
            freesize -= dma_reserve;
            printk(KERN_DEBUG &quot;  %s zone: %lu pages reserved\n&quot;,
                    zone_names[0], dma_reserve);
        }

        if (!is_highmem_idx(j))
            nr_kernel_pages += freesize;
        /* Charge for highmem memmap if there are enough kernel pages */
        else if (nr_kernel_pages &gt; memmap_pages * 2)
            nr_kernel_pages -= memmap_pages;
        nr_all_pages += freesize;

        zone-&gt;spanned_pages = size;
        zone-&gt;present_pages = realsize;
        /*
         * Set an approximate value for lowmem here, it will be adjusted
         * when the bootmem allocator frees pages into the buddy system.
         * And all highmem pages will be managed by the buddy system.
         */
        zone-&gt;managed_pages = is_highmem_idx(j) ? realsize : freesize;
#ifdef CONFIG_NUMA
        zone-&gt;node = nid;
        zone-&gt;min_unmapped_pages = (freesize*sysctl_min_unmapped_ratio)
                        / 100;
        zone-&gt;min_slab_pages = (freesize * sysctl_min_slab_ratio) / 100;
#endif
        zone-&gt;name = zone_names[j];
        spin_lock_init(&amp;zone-&gt;lock);
        spin_lock_init(&amp;zone-&gt;lru_lock);
        zone_seqlock_init(zone);
        zone-&gt;zone_pgdat = pgdat;
        /* 初始化per-cpu成员变量pageset */
        zone_pcp_init(zone);

        /* For bootup, initialized properly in watermark setup */
        mod_zone_page_state(zone, NR_ALLOC_BATCH, zone-&gt;managed_pages);
        /* 初始化成员变量lruvec */
        lruvec_init(&amp;zone-&gt;lruvec);
        if (!size)
            continue;

        set_pageblock_order();
        /* sparse模型下为空 */
        setup_usemap(pgdat, zone, zone_start_pfn, size);
        /* 初始化zone的wait_table和free_area域 */
        ret = init_currently_empty_zone(zone, zone_start_pfn,
                        size, MEMMAP_EARLY);
        BUG_ON(ret);
        /* 设置zone内页框对应的struct page信息 */
        memmap_init(size, nid, j, zone_start_pfn);
        zone_start_pfn += size;
    }
}
</code></pre>

<h1 id="5-总结">5. 总结</h1>

<p>至此，Linux内核管理内存需要的数据结构，包括mem_section，NODE_DATA，zonelist初始化完成。</p>

<p>虽然内核在管理内存时，还会使用slab cache分配小片内存，但是建立slab cache还是要操作上面的数据结构。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">Globs Guo</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2019-10-12 100:100
        
    </span>
  </p>
  
  
</div>
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">Reward</label>
  <div class="qr-code">
    
    <label class="qr-code-image" for="reward">
        <img class="image" src="/img/reward/wechat.png">
        <span>wechat</span>
      </label>
    <label class="qr-code-image" for="reward">
        <img class="image" src="/img/reward/alipay.png">
        <span>alipay</span>
      </label>
  </div>
</div><footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kernel-sources/">kernel sources</a>
          <a href="/tags/memory-model/">memory model</a>
          <a href="/tags/vmemmap/">vmemmap</a>
          <a href="/tags/node_data/">NODE_DATA</a>
          <a href="/tags/zonelist/">zonelist</a>
          <a href="/tags/mem_section/">mem_section</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/memory_policy/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Linux Memory Policy</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/mm-slab/">
            <span class="next-text nav-default">mm-slab</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  
    <script src="https://utteranc.es/client.js"
            repo="GlobsGuo/utterancesRepo"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/utterance">comments powered by utterances.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="sendtomedivh@126.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/globsguo" class="iconfont icon-github" title="github"></a>
  <a href="https://globsguo.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Globs Guo</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"  integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>








</body>
</html>
