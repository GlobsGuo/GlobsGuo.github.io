<!DOCTYPE html>
<html lang="en-us">
    
    


    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.58.3" />

    
    
    

<title>Linux Memory Policy • Globs&#39; blog</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Linux Memory Policy"/>
<meta name="twitter:description" content="内核中，内存策略决定了NUMA系统中分配内存的节点。
内存策略和cpuset不同，后者是限制进程内存分配节点的管理机制，而内存策略是NUMA-aware应用可以使用的编程接口。二者同时应用在进程时，cpuset优先级更高。
1. Memory Policy Concepts 1.1. Scope of Memory Policies 内核支持内存策略的scope，从最一般的情况到最特殊的情况为："/>

<meta property="og:title" content="Linux Memory Policy" />
<meta property="og:description" content="内核中，内存策略决定了NUMA系统中分配内存的节点。
内存策略和cpuset不同，后者是限制进程内存分配节点的管理机制，而内存策略是NUMA-aware应用可以使用的编程接口。二者同时应用在进程时，cpuset优先级更高。
1. Memory Policy Concepts 1.1. Scope of Memory Policies 内核支持内存策略的scope，从最一般的情况到最特殊的情况为：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://globsguo.github.io/posts/memory_policy/" />
<meta property="article:published_time" content="2019-10-12T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-10-12T00:00:00+00:00" /><meta property="og:site_name" content="Globs&#39; blog" />


    


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">








<link rel="stylesheet" href="/scss/hyde-hyde.9181f25ed2263aeb878ec6f8a84f10c4ebb16150000fca8767308880bdde5ca0.css" integrity="sha256-kYHyXtImOuuHjsb4qE8QxOuxYVAAD8qHZzCIgL3eXKA=">


<link rel="stylesheet" href="/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    
</head>


    <body class=" ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="https://globsguo.github.io/">Globs&#39; blog</a>
      </span>
      
        
        
        
        <div class="author-image">
          <img src="https://globsguo.github.io/img/photo.jpg" alt="Author Image" class="img--circle img--headshot element--center">
        </div>
        
      
      
      <p class="site__description">
        
      </p>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">Globs&#39; blog</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="/posts/">
						<span>Posts</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/portfolio/">
						<span>Portfolio</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/about/">
						<span>About</span>
					</a>
				</li>
			 
		
	</ul>
</div>

        <section class="social">
	
	
	
	<a href="https://github.com/globsguo" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	<a href="mailto:sendtomedivh@126.com" rel="me"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
</section>

      </div>
    </div>
    
<div class="copyright">
  &copy; 2019 Globs Guo
  
</div>



  </div>
</div>

        <div class="content container">
            
    
<article>
  <header>
    <h1>Linux Memory Policy</h1>
    
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Oct 12, 2019
    
    
    
    
    
      
      
          <br/>
           <i class="fas fa-tags"></i>
          
          <a class="badge badge-tag" href="/tags/documentation">documentation</a>
           
      
          <a class="badge badge-tag" href="/tags/memory-policy">memory policy</a>
           
      
          <a class="badge badge-tag" href="/tags/cpuset">cpuset</a>
           
      
          <a class="badge badge-tag" href="/tags/cgroup">cgroup</a>
          
      
    
    
    <br/>
    <i class="fas fa-clock"></i> 2 min read
</div>


  </header>
  
  
  <div class="post">
    

<p>内核中，内存策略决定了NUMA系统中分配内存的节点。</p>

<p>内存策略和cpuset不同，后者是限制进程内存分配节点的管理机制，而内存策略是NUMA-aware应用可以使用的编程接口。二者同时应用在进程时，cpuset优先级更高。</p>

<h1 id="1-memory-policy-concepts">1. Memory Policy Concepts</h1>

<h2 id="1-1-scope-of-memory-policies">1.1. Scope of Memory Policies</h2>

<p>内核支持内存策略的scope，从最一般的情况到最特殊的情况为：</p>

<ul>
<li><p>系统的默认策略<br />
hard coded到内核中，管理所有不受其他策略控制的内存页。系统启动运行后，系统的默认策略为&rdquo;local allocation&rdquo;。然而在系统启动阶段，系统的默认策略为所有节点之间的interleave分配，</p></li>

<li><p>Task/Process Policy<br />
可选的，per-task策略，如果进程不受其他更具体的策略控制，该策略控制进程所有的内存页的分配。如果进程没有定义进程策略，所有由进程策略控制的内存页分配都回滚到系统默认的策略。<br />
进程策略适用于进程的整个地址空间，因此可以通过<code>fork()</code>(带有CLONE_VM标志的<code>clone()</code> w/o)和<code>exec*()</code>遗传，方便父进程为子进程创建内存策略。<br />
至于多线程的进程，进程策略只适用于安装策略的线程(Linux kernel task)，以及由该线程创建的线程。安装策略时存在的其他兄弟线程有自己策略。<br />
只有在安装以后，策略才能对页面分配操作生效，之前所有已经分配的页面都会保持原有的内存策略不变。</p></li>

<li><p>VMA策略<br />
VMA指virtual memory area，即进程的虚拟地址空间的一段区域，一个进程可以为自己的虚拟地址空间的一部分定义一个特殊的策略。通过<code>mbind()</code>系统调用实现。<br />
VMA策略管理所有属于该段地址空间的内存页分配，没有VMA策略的地址空间由进程策略管理，或者系统的默认策略。</p></li>
</ul>

<p>VMA策略有一些复杂的细节：
  - 只适用于匿名页，包括分配给匿名段的页，比如进程的堆和栈，以及通过设置了MAP_ANONYMOUS标志的<code>mmap()</code>的地址空间。设置了MAP_SHARED标志的文件映射的VMA策略会被忽略。如果文件映射使用了MAP_PRIVATE标志，只有针对映射的写操作分配的匿名页才会应用VMA策略，比如copy-on-write。
  - VMA策略在所有共享一个虚拟地址空间的进程之间共享——比如线程，无论何时安装策略，并且通过<code>fork()</code>继承。由于VMA策略指向进程的一段具体的地址空间，而执行<code>exec*()</code>时会重新创建地址空间，VMA策略无法通过<code>exec()</code>继承。因此，只有NUMA-aware应用可以使用VMA策略。
  - 进程可以只针对之前<code>mmap()</code>区域的一部分安装新的VMA策略，内核会将已有的虚拟地址空间分成2或3个VMA，每个都有自己的策略。
  - 默认情况下只有VMA策略安装后的页面分配操作才能生效，之前已经分配的页面仍然由分配时的策略管理。2.6.16以后的版本，Linux支持通过<code>mbind()</code>系统调用实现页面迁移，旧的页面可以被移动，应用新的策略。</p>

<ul>
<li>共享策略<br />
共享策略适用于映射到一个或多个进程的不同地址空间并且由这些进程共享的&rdquo;内存对象&rdquo;，和VMA策略的使用方法相同，通过<code>mbind()</code>系统调用指明映射共享对象的虚拟地址范围。VMA策略可以视为某段进程地址空间的一个属性，与之不同的是，共享策略直接应用于共享对象。因此，关联到对象的所有进程都会共享策略；任何进程分配给共享对象的所有页面都会遵从共享策略。<br />
2.6.22内核，只有<code>shmget()</code>或者<code>mmap(MAP_ANONYMOUS|MAP_SHARED)</code>创建的共享内存段支持共享策略。共享策略的支持添加到Linux时，相关的数据结构会添加到hugetlbfs shmem segments。目前，hugetlbfs不支持在缺页时分配，因此hugetlbfs shmem segments不支持共享策略。<br />
正如之前所述(VMA策略)，通过MAP_SHARED<code>mmap()</code>的普通文件的页高速缓存的内存页分配操作会忽略共享文件映射的虚拟地址上安装的任何VMA策略。页高速缓存的共享内存页，包括进程没有写过的通过MAP_PRIVATE映射的内存页，遵守进程策略，或者系统默认策略。<br />
共享策略的基本结构支持共享对象的子地址空间采用不同的策略，为此Linux将安装策略的进程的VMA分割，以支持多个不同的策略。因此，关联到同一共享内存段的不同进程可能有不同的VMA配置，可以通过 */proc/&lt;pid&gt;/numa_maps*文件查看。</li>
</ul>

<h2 id="1-2-components-of-memory-policies">1.2. Components of Memory Policies</h2>

<p>Linux的内存策略包括“mode”，可选的模式标志，和可选的节点集。模式决定策略的行为，可选的模式标志决定模式的行为，可选的节点集作为策略行为的参数。</p>

<p>从内部来看，内存策略通过 <strong>struct mempolicy</strong> 结构实现，在下文的contents of memory policy部分详细介绍。</p>

<h3 id="1-2-1-mode-of-memory-policy">1.2.1. Mode of Memory Policy</h3>

<p>Linux的内存策略支持4中行为模式：</p>

<ul>
<li><p>默认模式——MPOL_DEFAULT<br />
只用于内存策略API，从内部来看，在所有的内存scope中MPOL_DEFAULT都被转化为NULL。指明MPOL_DEFAULT时，任何已有的非默认策略都会被移除。于是，MPOL_DEFAULT意味着“回退到下一个最特殊的内存scope”。<br />
例如，一个NULL或者默认进程策略会回退到系统默认策略；一个NULL或者默认VMA策略会回退到进程策略。<br />
使用内存策略的API时，默认模式不使用可选的节点集。如果节点集非空，会产生错误。</p></li>

<li><p>MPOL_BIND<br />
意为使用的内存必须来自策略指明的节点集，由距离分配操作所在的节点最近的，并且有足够的空闲内存的节点分配内存。</p></li>

<li><p>MPOL_PREFERRED<br />
尝试用策略指明的单个节点完成分配操作，如果失败，内核会寻找其他节点，按照距离首选的节点由近到远的顺序。<br />
从内部来看，首选的策略使用单个节点——struct mempolicy的 <strong>preferred_node</strong> 成员。如果设置了内部的模式标志MPOL_F_LOCAL， <strong>preferred_node</strong> 就会被忽略，策略会被视为本地的分配。本地的分配策略可以视为从包含发生分配操作的CPU的节点开始的首选策略。<br />
用户也可以通过设置空的节点表明本地节点是首选节点，设置空节点时，不能同时使用MPOL_F_STATIC_NODES和MPOL_F_RELATIVE_NODES。</p></li>

<li><p>MPOL_INTERLEAVED<br />
页面分配以页的粒度，在策略指明的节点间进行间隔分配。在不同的使用情形中，可能有不同的行为：</p>

<ul>
<li>对于匿名页和共享内存页的分配，间隔模式通过发生缺页的地址的页内偏移对策略指明的内存节点数取整来索引策略指明的内存节点。之后从所选的节点开始，尝试进行页面分配，就像节点通过首选策略或者本地分配指明。也就是说，分配操作会遵循per node zonelist。</li>
<li>对于页高速缓存页面的分配，间隔模式使用由每个进程维护的节点计数器索引由策略指明的节点。计数器达到指明的最大节点后，回到最小的节点。这样，分配的页面会平均分配到所有的节点，基于页面的分配次序，而不是基于页面的偏移量。系统启动阶段，临时的系统默认策略的间隔模式按照此种模式运行。</li>
</ul></li>
</ul>

<h3 id="1-2-2-可选的模式标志">1.2.2. 可选的模式标志</h3>

<ul>
<li><p>MPOL_F_STATIC_NODES<br />
如果进程或者VMA的节点在内存策略定义后发生了变化，用户指定的节点掩码不要进行重映射。<br />
如果没有指明这个标志，任何时候发生了指定的内存节点集的改变导致内存策略的重新绑定，节点(首选的)或者节点掩码(bind，interleave)都会重新映射到新的节点集。这可能导致之前不需要的节点被使用。<br />
如果指明了这个标志，用户指明的节点和进程的cpuset允许的节点重叠时，内存策略应用于二者的交集。如果两个节点没有重叠，使用默认的策略。<br />
例如，关联到使用mems 1-3的cpuset的进程，使用间隔策略，设置相同的内存节点集。如果cpuset的mems变成了3-5，间隔就会在节点3，4，5进行。设置了这个标志，间隔只会在节点3发生。<br />
MPOL_F_STATIC_NODES和MPOL_F_RELATIVE_NODES不能组合使用，也不能用于通过空节点掩码创建的MPOL_PREFERRED策略。</p></li>

<li><p>MPOL_F_RELATIVE_NODES<br />
用户指明的节点掩码会被映射为进程或者VMA的相对节点，内核保存用户传递的节点掩码，如果指明的节点改变，原始的节点掩码会被重新映射到新节点。<br />
如果没有指明这个标志(也没有MPOL_F_STATIC_NODES)，任何时候节点的变化导致的内存策略的重新绑定，节点(首选的)或者节点掩码(bind，interleave)都会重新映射到新的节点。重新绑定操作导致的重映射操作可能不会保存用户传递的节点掩码的相对性质：原本为1，3，5的节点掩码可能会被重映射为7-9，而在恢复到原始状态时变成1-3。<br />
如果设置了这个标志，用户指明的节点掩码就是一个相对值。例如，设置了MPOL_F_RELATIVE_NODES的间隔策略，cpuset和内存节点都是为mems 2-5。如果cpuset mems变成3-7，间隔在节点3，5-7之间发生(2-5指的是3，5-7的第2，3，4，5个节点，从0开始，超出范围的从头计)。<br />
MPOL_F_RELATIVE_NODES不能和MPOL_F_STATIC_NODES同时使用，也不能用于节点掩码为空的MPOL_PREFERRED策略。</p></li>
</ul>

<h1 id="2-memory-policy-reference-counting">2. Memory Policy Reference Counting</h1>

<p>为了解决user/free的竞争问题， <strong>struct mempolicy</strong> 包含一个原子的引用计数成员，内部的接口<code>mpol_get()/mpol_put()</code>可以增加/减少这个引用计数。如果引用计数减少到零，<code>mpol_put()</code>函数只会将 <strong>struct mempolicy</strong> 释放到mempolicy kmem cache。</p>

<p>分配新的内存策略时，引用计数初始化为1，表示安装这个策略的进程正在应用该结构。如果内存策略的指针被保存到另一个结构体，引用计数也会增加——因为进程的引用在策略安装完成后会被移除。</p>

<p>策略的运行时“usage”，我们试图最小化引用计数的原子操作，有利于CPU和NUMA节点之间的cache line健壮性。这些“usage”包括以下情况：</p>

<ol>
<li>进程自己(通过<code>get_mempolicy()</code>API)或者其他进程(通过 */proc/&lt;pid&gt;/numa_maps*文件)查询策略时</li>
<li>测试策略以判断策略模式和关联的用于页面分配的节点列表，被视为“hot path”。对于MPOL_BIND，“usage”扩展到整个分配过程，由于BIND策略会过滤掉不合格的节点，可能在页面回收过程中休眠。</li>
</ol>

<p>下列情形中，无需增加引用计数：</p>

<ol>
<li>默认策略不会被改变，也不会被释放，无需执行get/free操作</li>
<li>查询策略时，会首先获取进程的 <strong>mmap_sem</strong> 以进行读取操作，不需要增加目标进程的进程策略和VMA策略的引用计数。安装或者替换进程或者VMA策略时，<code>set_mempolicy()</code>和<code>mbind()</code>API会获取 <strong>mmap_sem</strong> 以执行写操作。因此，不存在一个进程或者线程正在释放一个策略的同时领一个进程或者线程正在查询该策略的可能性。</li>
<li>使用进程或者VMA策略，持有 <strong>mmap_sem</strong> 读取策略时发生的页面分配操作。因为替换进程或者VMA策略执行的写操作需要 <strong>mmap_sem</strong> ，执行页面分配操作时，策略不可能被释放。</li>
<li>共享策略需要特殊对待，一个进程在持有不同的 <strong>mmap_sem</strong> 时可以针对策略查询或者分配内存页的同时，另一个进程可能替换共享的内存策略。要解决这个潜在的竞争问题，共享策略的管理数据结构中增加了一个自旋锁，添加了一个额外的引用计数。这就需要我们在使用策略过后移除额外的引用计数。我们必须在和非共享策略的相同query/allocation路径上移除额外的引用计数。<br />
由于额外的引用计数，以及必须在持有自旋锁的情况下对树状共享策略进行查询操作，共享策略的页面分配函数路径开销更大，尤其是运行在不同NUMA节点的进程。将共享内存区域的内存策略回退到进程策略或者系统的默认策略可以避免额外的开销，或者对整片共享的内存区域提前执行缺页操作，并且固定到内存中。</li>
</ol>

<h1 id="3-memory-policy-apis">3. Memory Policy APIs</h1>

<p>Linux提供了三个控制内存策略的系统调用，这些API通常只会影响调用进程、调用进程的地址空间、或者映射到调用进程的地址空间的共享对象。</p>

<h2 id="3-1-设置-进程的-内存策略">3.1. 设置(进程的)内存策略</h2>

<pre><code class="language-C">long set_mempolicy(int mode, const unsigned long *nmask,  
            unsigned long maxnode)
</code></pre>

<p>设置调用进程的进程内存策略为参数mode指明的模式，nmask指明的节点。nmask指明的节点至少包含maxnode。可选的模式标志可以通过mode参数的组合传递。</p>

<h2 id="3-2-获取-进程的-内存策略或者相关的信息">3.2. 获取(进程的)内存策略或者相关的信息</h2>

<pre><code class="language-C">long get_mempolicy(int *mode, const unsigned long *nmask,  
            unsigned long maxnode, void *addr, int flags)
</code></pre>

<p>查询调用进程的进程内存策略，或者指明的虚拟地址策略或者location，取决于flags参数。</p>

<h2 id="3-3-安装vma-共享的内存策略到一段地址空间">3.3. 安装VMA/共享的内存策略到一段地址空间</h2>

<pre><code class="language-C">long bind(void *start, unsigned long len, int mode,
            const unsigned long *nmask,
            unsigned long maxnode, unsigned flags)

</code></pre>

<p><code>mbind()</code>安装(mode, nmask, maxnodes)指明的VMA策略到调用进程通过start和len参数确定的地址空间，额外的操作可以通过flags参数指明。</p>

<h1 id="4-command-line-interface">4. Command Line Interface</h1>

<p>命令行工具numactl可以通过 <code>set_mempolicy</code> 、 <code>fork</code> 、 <code>exec</code> 设置进程策略，也可以通过 <code>mbind</code> 设置共享内存段的共享策略。</p>

<h1 id="5-memory-policies-and-cpusets">5. Memory Policies and Cpusets</h1>

<p>内存策略受到cpuset的限制，如果节点掩码确定的内存节点不包含在cpuset，MPOL_F_RELATIVE_NODES没有设置，就会使用二者的交集。如果结果为空，内存策略会被视为无效，不能安装。</p>

<p>两个cpuset中的进程共享同一片内存区域时，内存策略和cpuset的交集可能带来问题。例如，设置了MAP_ANONYMOUS和MAP_SHARED标志的<code>mmap()</code>后通过<code>shmget()</code>创建的共享内存段，任何进程在该内存区域安装共享策略，只有同时包含在两个cpuset中的节点可以由策略使用。</p>

  </div>
  

<div class="navigation navigation-single">
    
    <a href="/posts/memory_management/" class="navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">Memory Management Initialization</span>
    </a>
    
    
    <a href="/posts/grub_parameters/" class="navigation-next">
      <span class="navigation-tittle">grub参数&#34;console=&#34;</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  

  
    
        <script src="https://utteranc.es/client.js"
        repo="https://github.com/globsguo/utterancesRepo"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
    


</article>


        </div>
        
    

<script defer src="https://use.fontawesome.com/releases/v5.5.0/js/all.js" integrity="sha384-GqVMZRt5Gn7tB9D9q7ONtcp4gtHIUEW/yG7h98J7IpE3kpi+srfFyyB/04OV6pG0" crossorigin="anonymous"></script>


    
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
        
    
    <script type="text/javascript">
        
        hljs.initHighlightingOnLoad();
    </script>
    




    



    </body>
</html>
